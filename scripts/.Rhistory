n_pots = n()) %>%
ungroup()
ggplot(exper) +
geom_bar(aes(x = Location, y = temp_avg),
stat = "identity") +
geom_errorbar(aes(x = Location, ymin = temp_avg - temp_sd, ymax = temp_avg + temp_sd)) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# Alright, neat little graph here! Looks like most sites have a broadly similar range of temperatures, with some exceptions. Port Camden in particular seems to be substantially higher than practically every other site!
# Let's look at how temperature relates to year!
exper <- pot_dat %>%
group_by(Year) %>%
summarize(temp_avg  = mean(temp),
temp_sd = sd(temp),
n_pots = n()) %>%
ungroup()
ggplot(exper) +
geom_bar(aes(x = Year, y = temp_avg),
stat = "identity") +
geom_errorbar(aes(x = Year, ymin = temp_avg - temp_sd, ymax = temp_avg + temp_sd)) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
#### Temp vs. time of year ----------------------------
# We'll use Julian day for this
exper <- pot_dat
exper$Jul.Day <- as.Date(exper$Time.Hauled)
exper$Jul.Day <- yday(exper$Jul.Day)
# First, a scatterplot of all temps and Julian days
ggplot(exper, aes(x = Jul.Day, y = temp)) +
geom_point()
# Alright, we can see an overall gentle curve, along with the timing of each survey (Tanner vs. RKC)
# Now, let's make a line plot!
exper <- exper %>%
group_by(Jul.Day) %>%
summarize(temp_avg = mean(temp))
ggplot(exper, aes( x= Jul.Day, y = temp_avg)) +
geom_line() +
geom_point()
# Now, let's make a line plot!
expersum <- exper %>%
group_by(Jul.Day) %>%
summarize(temp_avg = mean(temp))
#### Temp vs. time of year ----------------------------
# We'll use Julian day for this
exper <- pot_dat
exper$Jul.Day <- as.Date(exper$Time.Hauled)
exper$Jul.Day <- yday(exper$Jul.Day)
# First, a scatterplot of all temps and Julian days
ggplot(exper, aes(x = Jul.Day, y = temp)) +
geom_point()
# Now, let's make a line plot!
expersum <- exper %>%
group_by(Jul.Day) %>%
summarize(temp_avg = mean(temp))
#### Temp vs. time of year ----------------------------
# We'll use Julian day for this
pot_dat$Jul.Day <- as.Date(pot_dat$Time.Hauled)
pot_dat$Jul.Day <- yday(pot_dat$Jul.Day)
# First, a scatterplot of all temps and Julian days
ggplot(pot_dat, aes(x = Jul.Day, y = temp)) +
geom_point()
# Now, let's make a line plot!
exper <- pot_dat %>%
group_by(Jul.Day) %>%
summarize(temp_avg = mean(temp))
ggplot(exper, aes( x= Jul.Day, y = temp_avg)) +
geom_line() +
geom_point()
#### Survey Date and Year ---------------------------------
exper <- pot_dat %>%
group_by(c(Jul.Day, Year))
group_by
?group_by
#### Survey Date and Year ---------------------------------
exper <- pot_dat %>%
group_by(Jul.Day, Year)
exper
#### Survey Date and Year ---------------------------------
exper <- pot_dat %>%
group_by(Trip.Start.Date)
exper
#### Survey Date and Year ---------------------------------
ggplot(pot_dat, aes(x = Year, y = Trip.Start.Date))
#### Survey Date and Year ---------------------------------
ggplot(pot_dat, aes(x = Year, y = Trip.Start.Date)) +
geom_point()
#### Survey Date and Year ---------------------------------
ggplot(pot_dat, aes(x = Jul.Day, y = Trip.Start.Date)) +
geom_point()
# Add all required libraries here
list.of.packages <- c("tidyverse", "lubridate", "ggridges")
# Get names of all required packages that aren't installed
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
# Install all new packages
if(length(new.packages)) install.packages(new.packages)
# Load all required libraries
lapply(list.of.packages, FUN = function(X) {
do.call("require", list(X))
})
#### Survey Date and Year ---------------------------------
# Create table of years of each survey
dates <- matrix(data = NA, nrow = 0, ncol = 4)
a <- 1:365
View(pot_dat)
# Add all required libraries here
list.of.packages <- c("tidyverse", "lubridate", "ggridges", "tidyquant")
# Add all required libraries here
list.of.packages <- c("tidyverse", "lubridate", "ggridges", "tidyquant")
# Get names of all required packages that aren't installed
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
# Install all new packages
if(length(new.packages)) install.packages(new.packages)
# Load all required libraries
lapply(list.of.packages, FUN = function(X) {
do.call("require", list(X))
})
View(pot_dat)
#### Temp vs. depth ---------------------------
# We'll look at the average depth of each site vs. the average temp
exper <- pot_dat %>%
group_by(Location) %>%
summarize(depth_avg  = mean(Depth.Fathoms),
temp_avg = mean(temp),
temp_sd = sd(temp),
depth_sd = sd(Depth.Fathoms),
n_pots = n()) %>%
ungroup()
exper
# First, depth of each site
ggplot(exper) +
geom_bar(aes(x = Location, y = depth_avg),
stat = "identity") +
geom_errorbar(aes(x = Location, ymin = depth_avg - depth_sd, ymax = depth_avg + depth_sd)) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# Now, depth vs. temperature
ggplot(exper, aes(x = depth_avg, y = temp_avg)) +
geom_point()
# First, depth of each site
ggplot(exper) +
geom_bar(aes(x = Location, y = depth_avg),
stat = "identity") +
geom_errorbar(aes(x = Location, ymin = depth_avg - depth_sd, ymax = depth_avg + depth_sd)) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# Now let's switch it up to maximum depth (more of an examination of the water bodies) and temperature
exper <- pot_dat %>%
group_by(Location) %>%
summarize(depth_max  = max(Depth.Fathoms),
temp_avg = mean(temp),
temp_sd = sd(temp),
n_pots = n()) %>%
ungroup()
# First, depth of each site
ggplot(exper) +
geom_bar(aes(x = Location, y = depth_max),
stat = "identity") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# Now, depth vs. temperature
ggplot(exper, aes(x = depth_max, y = temp_avg)) +
geom_point()
# First, depth of each site
ggplot(exper) +
geom_bar(aes(x = Location, y = depth_max),
stat = "identity") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# Now, depth vs. temperature
ggplot(exper, aes(x = depth_max, y = temp_avg)) +
geom_point()
# First, depth of each site
ggplot(exper) +
geom_bar(aes(x = Location, y = depth_avg),
stat = "identity") +
geom_errorbar(aes(x = Location, ymin = depth_avg - depth_sd, ymax = depth_avg + depth_sd)) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
#### Temp vs. depth ---------------------------
# We'll look at the average depth of each site vs. the average temp
exper <- pot_dat %>%
group_by(Location) %>%
summarize(depth_avg  = mean(Depth.Fathoms),
temp_avg = mean(temp),
temp_sd = sd(temp),
depth_sd = sd(Depth.Fathoms),
n_pots = n()) %>%
ungroup()
# First, depth of each site
ggplot(exper) +
geom_bar(aes(x = Location, y = depth_avg),
stat = "identity") +
geom_errorbar(aes(x = Location, ymin = depth_avg - depth_sd, ymax = depth_avg + depth_sd)) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# Now, depth vs. temperature
ggplot(exper, aes(x = depth_avg, y = temp_avg)) +
geom_point()
# Now let's switch it up to maximum depth (more of an examination of the water bodies) and temperature
exper <- pot_dat %>%
group_by(Location) %>%
summarize(depth_max  = max(Depth.Fathoms),
temp_avg = mean(temp),
temp_sd = sd(temp),
n_pots = n()) %>%
ungroup()
# First, depth of each site
ggplot(exper) +
geom_bar(aes(x = Location, y = depth_max),
stat = "identity") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# Now, depth vs. temperature
ggplot(exper, aes(x = depth_max, y = temp_avg)) +
geom_point()
View(exper)
View(crab_dat)
View(pot_dat)
# Now let's switch it up to maximum depth (more of an examination of the water bodies) and temperature
exper <- pot_dat %>%
group_by(Location) %>%
summarize(depth_max  = max(Depth.Fathoms),
temp_avg = mean(temp),
temp_sd = sd(temp),
n_pots = n(),
avg_day = mean(Jul.Day),
day_sd = sd(Jul.Day))%>%
ungroup()
# First, depth of each site
ggplot(exper) +
geom_bar(aes(x = Location, y = depth_max),
stat = "identity") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# Now, depth vs. temperature
ggplot(exper, aes(x = depth_max, y = temp_avg)) +
geom_point()
# What about average date each site was sampled?
ggplot(exper) +
geom_bar(aes(x = Location, y = avg_day),
stat = "identity") +
geom_errorbar(aes(x = Location, ymin = avg_day - day_sd, ymax = avg_day + day_sd)) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
# Hmm, alright. Looks like a few of the sites are specific to the later survey, while most aren't.
# Let's verify this with a table
table(pot_dat$Location, pot_dat$Project)
View(pot_dat)
View(crab_dat)
View(pot_dat)
# One thing I'm concerned about is a strong relationship between temperature and date. Let's figure that out
corr(pot_dat$temp, pot_dat$Jul.Day)
# One thing I'm concerned about is a strong relationship between temperature and date. Let's figure that out
cor(pot_dat$temp, pot_dat$Jul.Day)
# Alright, that's acceptable! Let's just graph it too
ggplot(pot_dat, aes(x = Jul.Day, y = temp)) +
geom_point()
# Let's also double check on latitude. Almost definitely fine, because our spatial scale is small, but hey
ggplot(pot_dat, aes(x = Latitude.Decimal.Degrees, y = temp)) +
geom_point()
knitr::opts_chunk$set(echo = TRUE)
# Add all required libraries here
list.of.packages <- c("tidyverse", "lme4", "MuMIn", "rcompanion", "MASS", "generalhoslem", "mgcv", "beepr", "regclass", "car", "DHARMa", "broom.mixed", "dotwhisker")
# Get names of all required packages that aren't installed
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
# Install all new packages
if(length(new.packages)) install.packages(new.packages)
# Load all required libraries
lapply(list.of.packages, FUN = function(X) {
do.call("require", list(X))
})
crab_dat <- read.csv(file = "../output/ADFG_SE_AK_pot_surveys/cleaned_data/crab_data/BCS_examined_crab_with_temperature.csv")
# See class of each column
str(crab_dat)
# Looks like we've got lots of columns that should be converted to factors!
crab_dat$Survey <- factor(crab_dat$Survey)
crab_dat$Site <- factor(crab_dat$Site)
crab_dat$Sex <- factor(crab_dat$Sex)
crab_dat$Recruit.Status <- factor(crab_dat$Recruit.Status)
crab_dat$Shell.Condition <- ordered(crab_dat$Shell.Condition)
crab_dat$Egg.Condition <- factor(crab_dat$Egg.Condition)
crab_dat$Egg.Development <- factor(crab_dat$Egg.Development)
crab_dat$Leg.Condition <- factor(crab_dat$Leg.Condition)
crab_dat$Bitter <- factor(crab_dat$Bitter)
crab_dat$Blackmat <- factor(crab_dat$Blackmat)
# See updated class of each column
str(crab_dat)
# CORRELATION BETWEEN CONTINUOUS VARIABLES
crab_nums <- select_if(crab_dat, is.numeric)
numcor <- cor(crab_nums, method = "pearson")
# See the resulting table
print(numcor)
# See if any correlations are > 0.6 (our bar for correlation) and less than 1 (since every variable is perfectly correlated with itself)
any(abs(numcor) > 0.6 & numcor < 1)
which(abs(numcor) > 0.6 & numcor < 1, arr.ind = TRUE)
# Looks like we have a tight correlation between latitude and longitude
# Temperature and Julian day are pretty close (corr = 0.56), but nothing else is above 0.5
# CORRELATIONS BETWEEN CATEGORICAL VARIABLES
# Now we're using Cramer's V test to look at correlation among our categorical variables
crabcat <- select_if(crab_dat, is.factor)
# Turn all from factors to numeric
crabcat[] <- sapply(crabcat, as.numeric)
# Initialize a blank matrix
results_matrix <- matrix(nrow = length(crabcat), ncol = length(crabcat))
# Name all rows and columns with our variable names
colnames(results_matrix) <- names(crabcat)
rownames(results_matrix) <- names(crabcat)
# Fill the matrix by performing Cramer's V test on each possible combination of factors
for (i in 1:ncol(crabcat)) {
for (j in 1:ncol(crabcat)) {
cramer.table <- table(crabcat[,i],crabcat[,j])
cramer.matrix <- as.matrix(cramer.table)
results_matrix[i,j] <- cramerV(cramer.matrix)
}
}
# See the resulting matrix
print(results_matrix)
# See if any of our correlations (aside from self-correlations) cross our boundary of too much correlation
any(results_matrix > 0.6 & results_matrix < 1)
which(abs(results_matrix) > 0.6 & results_matrix < 1, arr.ind = TRUE)
# Tight correlation between survey and site, which is fine - we weren't planning to include survey in any model
# Correlations of 1 between recruit status and sex too, indicating we should choose one for our models
#       We'll pick sex, since recruit status is mostly captured by sex + CW
# No other strong correlations
# CORRELATIONS BETWEEN CATEGORICAL AND CONTINUOUS VARIABLES
# We'll use Spearman rank-order correlation to determine whether we have any correlation
crabrank <- crab_dat
crabrank[] <- sapply(crab_dat, as.numeric)
crabcomps <- cor(crabrank, method = "spearman")
any(abs(crabcomps) > 0.6 & crabcomps < 1)
# Looks like we do have some significant correlations this time! Let's pull them out
which(abs(crabcomps) > 0.6 & crabcomps < 1, arr.ind = TRUE)
print(crabcomps)
# Correlations are between:
# Julian day and survey (don't care, not including survey in model)
# Recruit status and CW (already decided to exclude recruit status from model since it's mostly CW + sex)
# Latitude and longitude (we'll likely just use latitude, or skip altogether and just use site)
# Temperature and Julian day (these are two continuous variables, which were already cleared using the more appropriate Pearson metric)
# Subtract 2004 from all years, so that our earliest year is 1
crab_dat$s.Year <- crab_dat$Year-(min(crab_dat$Year)-1)
# Scale chela height, egg percent, latitude, longitude, Julian day, depth, and temperature
crab_dat$s.Chela.Ht <- scale(crab_dat$Chela.Ht)
crab_dat$s.Egg.Percent <- scale(crab_dat$Egg.Percent)
crab_dat$s.Latitude <- scale(crab_dat$Latitude)
crab_dat$s.Longitude <- scale(crab_dat$Longitude)
crab_dat$s.Jul.Day <- scale(crab_dat$Jul.Day)
crab_dat$s.Depth <- scale(crab_dat$Depth)
crab_dat$s.Temp <- scale(crab_dat$Temp)
# We'll scale CW twice - once for males, and once for females. This'll capture the sexual dimorphism within Tanner crabs
crab_dat_f <- crab_dat[crab_dat$Sex == "2", ]
crab_dat_m <- crab_dat[crab_dat$Sex == "1", ]
crab_dat_f$s.CW <- scale(crab_dat_f$CW)
crab_dat_m$s.CW <- scale(crab_dat_m$CW)
crab_dat <- rbind(crab_dat_f, crab_dat_m)
View(crab_dat)
# Create new data table called mat_crabs
mat_crabs <- crab_dat
# Get maturity for male crabs
# Same process as before - using the ratio of chela height to carapace width to indicate male maturity
# Note: This is using the EBS line for height-CW, will have to get the SE AK ratio later
# EBS equation = ln(chela_ht) = (1.189*ln(CW)) - 2.674
# Create new column for maturity line. Remember, log() computes ln, R is weird like that
# Also, male crabs with a CW < 60 are immature
mat_crabs$mat_line <- (1.189 * log(mat_crabs$CW)) - 2.674
# Create new data table called mat_crabs
mat_crabs <- crab_dat
# Get maturity for male crabs
# Same process as before - using the ratio of chela height to carapace width to indicate male maturity
# Note: This is using the EBS line for height-CW, will have to get the SE AK ratio later
# EBS equation = ln(chela_ht) = (1.189*ln(CW)) - 2.674
# Create new column for maturity line. Remember, log() computes ln, R is weird like that
# Also, male crabs with a CW < 60 are immature
mat_crabs$mat_line <- (1.189 * log(mat_crabs$CW)) - 2.674
?case_when
# Create column for maturity status
mat_crabs <- mat_crabs %>%
mutate(mat_stat = case_when(
mat_val <= mat_line | CW <= 60 ~ "1",
mat_val > mat_line ~ "2"
))
# Create new data table called mat_crabs
mat_crabs <- crab_dat
# Get maturity for male crabs
# Same process as before - using the ratio of chela height to carapace width to indicate male maturity
# Note: This is using the EBS line for height-CW, will have to get the SE AK ratio later
# EBS equation = ln(chela_ht) = (1.189*ln(CW)) - 2.674
# Create new column for maturity line. Remember, log() computes ln, R is weird like that
# Also, male crabs with a CW < 60 are immature
mat_crabs$mat_line <- (1.189 * log(mat_crabs$CW)) - 2.674
# Calculate maturity value. If greater than maturity line and CW >= 60 cm, is mature
mat_crabs$mat_val <- log(mat_crabs$Chela.Ht)
# Create column for maturity status
mat_crabs <- mat_crabs %>%
mutate(mat_stat = case_when(
mat_val <= mat_line | CW <= 60 ~ "1",
mat_val > mat_line ~ "2"
))
View(mat_crabs)
table(mat_crabs$Recruit.Status)
table(mat_crabs$Recruit.Status, mat_crabs$Sex)
# Create column for maturity status
mat_crabs <- mat_crabs %>%
mutate(mat_stat = case_when(
mat_val <= mat_line | CW <= 60 | Recruit.Status == "Juvenile_Female" ~ "1",
mat_val > mat_line | Recruit.Status == "Mature_Female" ~ "2"
))
table(mat_crabs$Recruit.Status, mat_crabs$mat_val)
table(mat_crabs$Recruit.Status, mat_crabs$mat_stat)
# Create column for maturity status
mat_crabs <- mat_crabs %>%
mutate(mat_stat = case_when(
mat_val <= mat_line | CW <= 60 | Recruit.Status == "Juvenile_Female" ~ "1",
mat_val > mat_line | Recruit.Status == "Mature_Female" ~ "2"
))
table(mat_crabs$Recruit.Status, mat_crabs$mat_stat)
table(mat_crabs$Recruit.Status, mat_crabs$mat_stat, mat_crabs$Sex)
# Create column for maturity status
mat_crabs <- mat_crabs %>%
mutate(mat_stat = case_when(
mat_val <= mat_line | CW <= 60 & Sex == 2 | Recruit.Status == "Juvenile_Female" ~ "1",
mat_val > mat_line | Recruit.Status == "Mature_Female" ~ "2"
))
table(mat_crabs$Recruit.Status, mat_crabs$mat_stat, mat_crabs$Sex)
# Create column for maturity status
mat_crabs <- mat_crabs %>%
mutate(mat_stat = case_when(
mat_val <= mat_line | CW <= 60 & Sex == 1 | Recruit.Status == "Juvenile_Female" ~ "1",
mat_val > mat_line | Recruit.Status == "Mature_Female" ~ "2"
))
table(mat_crabs$Recruit.Status, mat_crabs$mat_stat, mat_crabs$Sex)
# Remove maturity value and line columns, no longer needed
mat_crabs <- mat_crabs %>%
select(-c(mat_val, mat_line))
# Remove maturity value and line columns, no longer needed
mat_crabs <- mat_crabs %>%
select(-c(mat_val, mat_line))
library(tidyverse)
# Remove maturity value and line columns, no longer needed
mat_crabs <- mat_crabs %>%
select(-c(mat_val, mat_line))
# Remove maturity value and line columns, no longer needed
mat_crabs <- mat_crabs %>%
tidyverse::select(-c(mat_val, mat_line))
?select
# Remove maturity value and line columns, no longer needed
mat_crabs <- mat_crabs %>%
dplyr::select(-c(mat_val, mat_line))
mat_dat <- crab_dat %>%
# Drop egg columns
mat_crabs <- mat_crabs %>%
select(-c(Egg.Development, Egg.Condition, Egg.Percent))
# Drop egg columns and chela height columns
mat_crabs <- mat_crabs %>%
dplyr::select(-c(Egg.Development, Egg.Condition, Egg.Percent, Chela.Ht))
# Drop lines without a value for maturity
mat_crabs <- mat_crabs[!is.na(mat_crabs$mat_stat), ]
# Drop scaled columns - we'll scale them again
mat_crabs <- mat_crabs %>%
select(-contains("s."))
# Drop scaled columns - we'll scale them again
mat_crabs <- mat_crabs %>%
dplyr::select(-contains("s."))
# See how many NAs we have
colSums(is.na(mat_crabs))
# Create new data table called mat_crabs
mat_crabs <- crab_dat
# Get maturity for male crabs
# Same process as before - using the ratio of chela height to carapace width to indicate male maturity
# Note: This is using the EBS line for height-CW, will have to get the SE AK ratio later
# EBS equation = ln(chela_ht) = (1.189*ln(CW)) - 2.674
# Create new column for maturity line. Remember, log() computes ln, R is weird like that
# Also, male crabs with a CW < 60 are immature
mat_crabs$mat_line <- (1.189 * log(mat_crabs$CW)) - 2.674
# Calculate maturity value. If greater than maturity line and CW >= 60 cm, is mature
mat_crabs$mat_val <- log(mat_crabs$Chela.Ht)
# Create column for maturity status
mat_crabs <- mat_crabs %>%
mutate(mat_stat = case_when(
mat_val <= mat_line | CW <= 60 & Sex == 1 | Recruit.Status == "Juvenile_Female" ~ "1",
mat_val > mat_line | Recruit.Status == "Mature_Female" ~ "2"
))
table(mat_crabs$Recruit.Status, mat_crabs$mat_stat, mat_crabs$Sex)
# Drop lines without a value for maturity
mat_crabs <- mat_crabs[!is.na(mat_crabs$mat_stat), ]
# Remove maturity value and line columns, no longer needed
mat_crabs <- mat_crabs %>%
dplyr::select(-c(mat_val, mat_line))
# Drop egg columns and chela height columns
mat_crabs <- mat_crabs %>%
dplyr::select(-c(Egg.Development, Egg.Condition, Egg.Percent, Chela.Ht))
# Drop scaled columns - we'll scale them again
mat_crabs <- mat_crabs %>%
dplyr::select(-contains("s."))
# See how many NAs we have
colSums(is.na(mat_crabs))
# Subtract 2004 from all years, so that our earliest year is 1
mat_crabs$s.Year <- mat_crabs$Year-(min(mat_crabs$Year)-1)
# Scale latitude, longitude, Julian day, depth, and temperature
mat_crabs$s.Latitude <- scale(mat_crabs$Latitude)
mat_crabs$s.Longitude <- scale(mat_crabs$Longitude)
mat_crabs$s.Jul.Day <- scale(mat_crabs$Jul.Day)
mat_crabs$s.Depth <- scale(mat_crabs$Depth)
mat_crabs$s.Temp <- scale(mat_crabs$Temp)
# We'll scale CW twice - once for males, and once for females. This'll capture the sexual dimorphism within Tanner crabs
mat_crabs_f <- mat_crabs[mat_crabs$Sex == "2", ]
mat_crabs_m <- mat_crabs[mat_crabs$Sex == "1", ]
mat_crabs_f$s.CW <- scale(mat_crabs_f$CW)
mat_crabs_m$s.CW <- scale(mat_crabs_m$CW)
mat_crabs <- rbind(mat_crabs_f, mat_crabs_m)
colnames(mat_crabs)
# Select all variables to be used in our model for male crabs
matcrabs_dat <- mat_crabs %>%
dplyr::select(c(s.Year, Site, Sex, s.CW, Shell.Condition, Leg.Condition, Bitter, Blackmat, s.Latitude, s.Jul.Day, s.Depth, s.Temp, mat_stat))
# Select independent variables
modeled_vars <- names(matcrabs_dat)
modeled_vars <- modeled_vars[!modeled_vars %in% c("s.Year", "Site", "Bitter")]
# Initialize dataframe with model values
AIC_vals <- matrix(nrow = length(modeled_vars), ncol = 2)
# Create a null model and get AIC
null_mod <- glmmTMB(Bitter ~ (1 | Site) + (1 | s.Year),
data = matcrabs_dat,
family = binomial,
na.action = "na.fail")
