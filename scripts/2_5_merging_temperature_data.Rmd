---
title: "2_4_merging_temperature_data"
author: "Aidan Coyle"
date: "7/25/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

In the previous script, we fixed file structure issues in our temperature data. Now, we'll incorporate the temperature data, which is included in .txt (and occasionally .csv) files. This is going to be a pain, so buckle up. Main issues are as follows:

- Temperature data is directly from data loggers that were in the pots. This means that they include both time at the bottom and time on deck.

- Data loggers are identified by the number in the filename

- In some surveys, data loggers were downloaded once (at the end of all legs). More commonly, they were downloaded at the end of each survey.

- Number of tidbits shift from year to year

- Best file to examine differs from year to year! Sometimes Tidbit files are individually numbered, other times they're already amalgamated into a master sheet

#### Load libraries (and install if necessary), and load packages

```{r libraries, message=FALSE, warning=FALSE}
# Add all required libraries here
list.of.packages <- c("tidyverse", "readxl", "lubridate")
# Get names of all required packages that aren't installed
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
# Install all new packages
if(length(new.packages)) install.packages(new.packages)


# Load all required libraries
lapply(list.of.packages, FUN = function(X) {
  do.call("require", list(X))
})

# Load custom functions
source("hemat_modeling_functions.R")
```

# Read in the Tidbit data for all years

```{r}
# For the sake of formatting, don't put a trailing / at the end of the path
full_dat <- read_tidbit_data(data_path = "../output/ADFG_SE_AK_pot_surveys/cleaned_data/temperature_data/2005")

years <- as.character(2006:2019)

for (i in 1:length(years)) {
  temp_dat <- read_tidbit_data(data_path = paste0("../output/ADFG_SE_AK_pot_surveys/cleaned_data/temperature_data/", years[i]))
  
  full_dat <- rbind(full_dat, temp_dat)
}


colSums(is.na(full_dat))

# Heck yes, no NA values!

# Now we'll check for weird values in all columns
table(full_dat$year)
table(full_dat$survey)
table(full_dat$tidbit_id)
head(sort(full_dat$tidbit_datetime))
head(sort(full_dat$tidbit_datetime, decreasing = TRUE))
head(sort(full_dat$Temp))
head(sort(full_dat$Temp, decreasing = TRUE))

# Max and min values all look good

# Convert formats to correct ones
full_dat$year <- as.numeric(full_dat$year)
full_dat$tidbit_datetime <- as_datetime(full_dat$tidbit_datetime, tz = "US/Alaska")

# To ensure all date/times were converted directly, check the hours for each year/survey combo
full_dat$hour <- hour(full_dat$tidbit_datetime)
table(full_dat$hour, full_dat$year)

# Everything looks great - no year has any sort of bias for pre-12pm, and values are typically within a few tens per hour.
full_dat <- full_dat %>%
  select(-hour)

# We'll double check that times weren't rounded by examining the distribution of minutes. Looking for odd numbers of :00
full_dat$min <- minute(full_dat$tidbit_datetime)

table(full_dat$min, full_dat$year)

# Looks good!!! (The excitement is because the first 20+ renditions were less successful).
full_dat[full_dat$tidbit_id == "17" & full_dat$year == 2016, ]

# We can now drop the min column
full_dat <- full_dat %>%
  select(-min)
```

We now have an extremely long dataframe consisting entirely of the following columns:
- year: 2005-2019
- survey: RKC or Tanner crab
- tidbit_id: A number unique to that year that identifies the Tidbit
- tidbit_datetime: The date and time measured by the Tidbit
- temp: The temperature measured by the Tidbit. 

Each row is one temperature measurement by one Tidbit. We want to do the following:

- Match each Tidbit with the pot it was in at the moment of measurement
- Average out temperatures across each pot deployment

To accomplish the first goal, we need to merge the Tidbit dataframe (described above) with our dataframe of pot data. However, due to the size of the Tidbit dataframe, it makes the most sense to do this on a year-by-year basis.

# Get the pot data cleaned up
```{r}
pot_dat <- read.csv(file = "../data/ADFG_SE_AK_pot_surveys/Pot_Set_Data_for_Tanner_and_RKC_surveys.csv")

# Remove spaces from column names
names(pot_dat) <- make.names(names(pot_dat), unique = TRUE)

# Eliminate columns we don't care about
pot_dat <- pot_dat %>%
  select(-c(Pot.Dimension.Feet, Pot.Escape.Device, Bait.Method, Weight.Of.Pot.Pounds,
            Pot.Type, Substrate.Type, Debris.Type))

# Change name of Tidbit ID column to match the one in use for tidbit_data
pot_dat <- rename(pot_dat, tidbit_id = Tidbit.No)

# Convert format of time columns from character to date
pot_dat$Time.Hauled <- mdy_hm(pot_dat$Time.Hauled, tz = "US/Alaska")
pot_dat$Time.Set <- mdy_hm(pot_dat$Time.Set, tz = "US/Alaska")

# Remove years before 2005 (first year with tidbits)
pot_dat <- pot_dat %>%
  filter(Year >= 2005)

# Check on frequency of tidbits
table(pot_dat$Year, pot_dat$tidbit_id, pot_dat$Project)

```

Despite having Tidbits, 2005-2007 have no tidbit_id values. After that, tidbit_id values are present for all surveys. 

A check of the data shows that in this years, tidbit_id is stored in the comments for these years. Additionally, it's often only in the comments for 2008. 
Oof, this is gonna take a while

We'll go through year by year and move comments into the tidbit_id section. We'll do this as follows:

1: Create new dataframe from pot_dat with post-2008 pot data
2: Create new dataframe from pot_dat with 2005 data, convert tidbit-related comments into tidbit_id values
3: Repeat step 2 with 2006, 2007, 2008 data
4: Merge 2005-2008 dataframes with dataframe created in Step 1. This'll be our new pot_dat column

##### 2005: Convert pot_dat comments to Tidbit IDs

```{r}
# Create version of pot_dat that only has years with tidbit_id info
full_pot_dat <- pot_dat %>%
  filter(Year >= 2009)

# Filter pot data to only include info from 2005 surveys
ohfive_pot_dat <- pot_dat %>%
  filter(Year == 2005)

tidbit_pots <- ohfive_pot_dat %>%
  filter(grepl("Tidbit", Pot.Comment, ignore.case = TRUE))

# Check we got all tidbit pots by looking at comments that don't match
non_tidbit_pots <- ohfive_pot_dat %>%
  filter(!grepl("Tidbit", Pot.Comment, ignore.case = TRUE))

# Yep, looks like tidbit_pots contains all 2005 tidbit pots!
# Now we need to extract the tidbit number
# In most, it's after a #

# Get all from single-digit tidbits 
tidbit_pots$tidbit_id <- str_extract(tidbit_pots$Pot.Comment, "#.")

# Overwrite single-digits that should be double-digits without adding NAs
# (prev. command read, say, #12 as #1)
new_dig <- str_extract(tidbit_pots$Pot.Comment, "#.\\d")
for (i in 1:length(new_dig)){
  if (!is.na(new_dig[i])){
    tidbit_pots$tidbit_id[i] <- new_dig[i]
  }
  else{}
}

# Remove the # from the column
tidbit_pots$tidbit_id <- gsub("#", "", tidbit_pots$tidbit_id)

# We still have a few left, but we can just add these manually
tidbit_pots[grep("5 Tidbit", tidbit_pots$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "5"
  
tidbit_pots[grep("11 Tidbit", tidbit_pots$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "11"

tidbit_pots[grep("10 Tidbit", tidbit_pots$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "10"

tidbit_pots[grep("7 Tidbit", tidbit_pots$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "7"

tidbit_pots[tidbit_pots$Pot.Comment == "Tidbit # 10 on this pot.", ]$tidbit_id <- "10"

tidbit_pots[tidbit_pots$Pot.Comment == "Tidbit 11 on this pot.", ]$tidbit_id <- "11"

# Alright, verify we did a good job here
any(is.na(tidbit_pots$tidbit_id))
table(tidbit_pots$tidbit_id)
# Looks great!

# Now we'll remerge the tidbit and non-tidbit pots to recreate the full 2005 dataset. It'll look the same, just with the Tidbit info added from the comments
ohfive_pot_dat <- rbind(tidbit_pots, non_tidbit_pots)
```

#### 2006: Convert pot_dat comments to Tidbit IDs

```{r}
ohsix_pot_dat <- pot_dat %>%
  filter(Year == 2006)

# All pots had some sort of comment noting the presence of Tidbits, so we don't need to filter
# out pots without tidbit references

# For most, the tidbit number is after an "#", so we'll just extract that.
ohsix_pot_dat$tidbit_id <- str_extract(ohsix_pot_dat$Pot.Comment, "#\\d{1,2}")

# For others, the tidbit number is just after "Tidbit", so we'll extract that too
new_digs <- str_extract(ohsix_pot_dat$Pot.Comment, "idbit \\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    ohsix_pot_dat$tidbit_id[i] <- new_digs[i]
  }
}

# For a few more, the tidbit number is after an "# " (ex: "Tidbit # 19"), so we'll extract that too
new_digs <- str_extract(ohsix_pot_dat$Pot.Comment, "# \\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    ohsix_pot_dat$tidbit_id[i] <- new_digs[i]
  }
}

# We still have a few left, but we can just add these manually
ohsix_pot_dat[grep("tidbit  20", ohsix_pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "20"
ohsix_pot_dat[grep("tidbit  13", ohsix_pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "13"
ohsix_pot_dat[grep("Tidibt 24", ohsix_pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "24"


# Alright, verify we did a good job here
ohsix_pot_dat[is.na(ohsix_pot_dat$tidbit_id), ]
# We have one NA, and it's a comment specifically noted as not having a tidbit. All good!
```
#### 2007: Convert pot_dat comments to Tidbit IDs

```{r}
ohseven_pot_dat <- pot_dat %>%
  filter(Year == 2007)

# All pots had some sort of comment noting the presence of Tidbits, so we don't need to filter
# out pots without tidbit references

# We'll add in all Tidbits after a # (no space)
new_digs <- str_extract(ohseven_pot_dat$Pot.Comment, "idbit #\\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
ohseven_pot_dat$tidbit_id <- new_digs

# Some Tidbit IDs didn't have the # (ex: Tidbit 19, not Tidbit #19), we'll add those too
new_digs <- str_extract(ohseven_pot_dat$Pot.Comment, "idbit \\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    ohseven_pot_dat$tidbit_id[i] <- new_digs[i]
  }
}

# Instead of being prefaced with "Tidbit", some are prefaced with "TB" or "tb" (ex: TB 14)
new_digs <- str_extract(ohseven_pot_dat$Pot.Comment, "TB \\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    ohseven_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}

new_digs <- str_extract(ohseven_pot_dat$Pot.Comment, "tb \\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    ohseven_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}


# Now an edge case - some Tidbits are four digits, with a dash, space, or underscore between the first and last set. For all, the last two digits are 07. Let's extract those.
new_digs <- str_extract(ohseven_pot_dat$Pot.Comment, "\\d{2}.07")
# Replace last 3 digits (either " 07", "-07", or "_07") with "07"
new_digs <- str_replace(new_digs, ".07", "-07")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    ohseven_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}

# We also have a few Tidbits where it's four digits ending in 07 (ex: 2007, not 20-07. We'll convert those too.)
new_digs <- str_extract(ohseven_pot_dat$Pot.Comment, "\\d{2}07")
# Replace last 3 digits (either " 07", "-07", or "_07") with "07"
new_digs <- str_replace(new_digs, "07", "-07")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    ohseven_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}

# We still have a few left, but we can just add these manually
ohseven_pot_dat[grep("tb  03", ohseven_pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "03"
ohseven_pot_dat[grep("tibit 11", ohseven_pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "11"
ohseven_pot_dat[grep("Tidbit  11", ohseven_pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "11"
ohseven_pot_dat[grep("Tidbit # 25", ohseven_pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "25"
ohseven_pot_dat[grep("TB 17.-07", ohseven_pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "17-07"
ohseven_pot_dat[grep("TB 2-07", ohseven_pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- "02-07"

# Alright, verify we did a good job here
ohseven_pot_dat[is.na(ohseven_pot_dat$tidbit_id), ]
# We have three NA, and none have comments noting tidbits. 
# All set!
```

#### 2008: Convert pot_dat comments to Tidbit IDs

```{r}
oheight_pot_dat <- pot_dat %>%
  filter(Year == 2008)

# All pots had some sort of comment noting the presence of Tidbits, so we don't need to filter
# out pots without tidbit references

# We'll add in all Tidbits after a # (no space)
new_digs <- str_extract(oheight_pot_dat$Pot.Comment, "#\\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    oheight_pot_dat$tidbit_id[i] <- new_digs[i]
  }
}

# Instead of being prefaced with "Tidbit", some are prefaced with "TB" or "tb" (ex: TB 14)
new_digs <- str_extract(oheight_pot_dat$Pot.Comment, "TB \\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    oheight_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}
new_digs <- str_extract(oheight_pot_dat$Pot.Comment, "tb \\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    oheight_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}
# Sometimes there's no space between the TB and the number (all these are capitalized). Let's fix
new_digs <- str_extract(oheight_pot_dat$Pot.Comment, "TB\\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    oheight_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}

# Now an edge case - some Tidbits are four digits, with a dash, space, or underscore between the first and last set. For all, the last two digits are 07. Let's extract those.
new_digs <- str_extract(oheight_pot_dat$Pot.Comment, "\\d{2}.07")
# Replace last 3 digits (either " 07", "-07", or "_07") with "07"
new_digs <- str_replace(new_digs, ".07", "-07")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    oheight_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}

# We also have a few Tidbits where it's four digits ending in 07 (ex: 2007, not 20-07. We'll convert those too.)
new_digs <- str_extract(oheight_pot_dat$Pot.Comment, "\\d{2}07")
# Replace last 3 digits (either " 07", "-07", or "_07") with "07"
new_digs <- str_replace(new_digs, "07", "-07")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    oheight_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}



# Alright, do a visual inspection. Looks good to me! We've got some overlap in tidbit names (ex: 20-07 and 2007), but we'll solve that later. 
```

### Merging all Pot Data

We now have five data tables - one for each year from 2005-2008 with accurate Tidbit IDs from that year, and one from 2009-2019 which already had accurate Tidbit IDs. Merge them all.

```{r}
pot_dat <- rbind(ohfive_pot_dat, ohsix_pot_dat, ohseven_pot_dat, oheight_pot_dat, full_pot_dat)

# Check other year comments for tidbit ID
tidbit_pots <- pot_dat %>%
  filter(grepl("Tidbit", Pot.Comment, ignore.case = TRUE)) %>%
  filter(Year > 2008)

# Alright, we've got a few notable commments, but almost none!
# Some tidbits are listed as missing, but have tidbit numbers in tidbit_id
# Others don't have a value in tidbit_id, but are listed in the comments
# Let's make some manual corrections
pot_dat[grep("no tidbit", pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- NA
pot_dat[grep("tidbit missing", pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- NA
pot_dat[grep("Pot open, no sample, Tidbit broken", pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- NA
pot_dat[grep("tidbit 10", pot_dat$Pot.Comment, ignore.case = TRUE), ]$tidbit_id <- 10

# Let's also check about values labeled "tb"
tidbit_pots <- pot_dat %>%
  filter(grepl("TB", Pot.Comment, ignore.case = TRUE)) %>%
  filter(Year > 2008)

# Yep, we've got a bunch. Bummer! Let's fix those. All are from 2009, so we'll specify
# Simplest way is gonna be just removing the 2009 data, editing it separately, then reading it back in
# That'll eliminate issues with, say, 2008 pots with "TB 2007" in the comments being read in as tidbit_id = 20

ohnine_pot_dat <- pot_dat %>%
  filter(Year == 2009)

pot_dat <- pot_dat %>%
  filter(Year != 2009)

new_digs <- str_extract(ohnine_pot_dat$Pot.Comment, "TB \\d{1,2}")
new_digs <- str_extract(new_digs, "\\d{1,2}")
for (i in 1:length(new_digs)){
  if (!is.na(new_digs[i])) {
    ohnine_pot_dat$tidbit_id[i] <- new_digs[i]
  } 
}

# Re-merge 2009 data in
pot_dat <- rbind(ohnine_pot_dat, pot_dat)

# Manually scan through comments from un-examined years to look for any unusual references to tidbits or loggers
test <- pot_dat %>%
  filter(Year > 2009)
# None found! We can safely remove the comments column
pot_dat <- pot_dat %>%
  select(-Pot.Comment)
```

# Merge Pot Data and Tidbit ID data

```{r}
# It won't work to merge both full dataframes at once (it's just too large - 400,000 rows x 10,000 rows)
# Instead, we'll try to merge each year individually using a for loop

# Initialize loop with matrix and vector of years
test_pot_merged <- matrix(nrow = 0, ncol = 20)
years <- 2005:2019


for (i in 1:length(years)){

  crab_year <- years[i]
  
  # Filter pot data and tidbit data to only include a single year
  year_pot <- pot_dat %>%
    filter (Year == crab_year)
  year_tidbit <- full_dat %>%
    filter(year == crab_year)
  # Join pot and tidbit data by tidbit ID
  year_dat <- inner_join(year_pot, year_tidbit, by = "tidbit_id")
  # Select only true entries by choosing rows where the data point is:
  #   - 2 min before time hauled (to account for small timekeeping errors)
  #   - 5 min after pot was set (to allow it to fall to the bottom)
  
  # Create new column calculating difference between tidbit time and haul time
  year_dat$change_time <- difftime(year_dat$tidbit_datetime, year_dat$Time.Hauled, tz = "US/Alaska", units = "mins")
  # Filter to only include rows 2+ min before haul time
  year_dat <- year_dat %>%
    filter(change_time < -2)
  
  # Change column to difference between tidbit time and set time
  year_dat$change_time <- difftime(year_dat$tidbit_datetime, year_dat$Time.Set, tz = "US/Alaska", units = "mins")
  # Filter to only include rows 5+ min after set time
  year_dat <- year_dat %>%
    filter(change_time > 5)
  
  # Remove column
  year_dat <- year_dat %>% 
    select(-change_time)
  
  # Calculate average temperature, adding a new column in the database for it
  year_dat <- year_dat %>%
    group_by(Time.Hauled) %>%
    mutate(mean_temp = mean(Temp)) %>%
    ungroup
  
  # Remove duplicate IDs from Time.Hauled. This leaves us with one row per haul. That eliminates temp (the specific measurements), date, time, and DateTime, but we don't care about that. 
  
  # It keeps average temperature of the pot, which is what we care about!
  
  year_dat <- year_dat[!duplicated(year_dat$Time.Hauled), ]
  
  # Append this to our merged data
  test_pot_merged <- rbind(test_pot_merged, year_dat)
}


```



# Junk


To avoid dealing with an unmanageably large dataset, we'll now merge the Tidbit data with the pot data from 2005.

```{r}

# Now we'll merge the tidbit data with the 2005 pot data based on Tidbit number. This will create a HUGE number of false entries, as each Tidbit entry will match to every deployment. 
full_data <- inner_join(ohfive_pot_dat, tidbit_data, by = "tidbit_id")

# Select only true entries by only choosing rows where the data point is from 2 minutes before the time hauled (to allow for small timekeeping errors) or 5 minutes after the pot was set (to allow it to fall to the bottom)
# 2 min before time hauled

# Create new column calculating difference between tidbit time and haul time, then filter
full_data$change_time <- difftime(full_data$tidbit_datetime, full_data$Time.Hauled, tz = "US/Alaska", units = "mins")
full_data <- full_data %>%
  filter(change_time < -2)
# Change column to difference between tidbit time and set time, then filter
full_data$change_time <- difftime(full_data$tidbit_datetime, full_data$Time.Set, tz = "US/Alaska", units = "mins")
full_data <- full_data %>%
  filter(change_time > 5)
# Remove column
full_data <- full_data %>%
  select(-change_time)

# Calculate average temperature, adding a new column in the database for it
full_data <- full_data %>%
  group_by(Time.Hauled) %>%
  mutate(mean_temp = mean(Temperature....C.)) %>%
  ungroup

# Remove duplicate IDs for Time.Hauled. This leaves us with one row per haul. That eliminates temp (the specific measurements), date, time, and DateTime, but
# we don't care about that. It keeps average temperature of the pot, which is what we care about!

full_data <- full_data[!duplicated(full_data$Time.Hauled), ]

# Rename this to complete_data
complete_data <- full_data

```



### 2006 Alt

The RKC data has already been assembled! It's not averaged out over time, but we have one row for each Tidbit timepoint, filtered to only include timepoints in which the Tidbit was in the water. We can just read that directly in as a new dataframe, which we'll call cleaned_tidbit_data

Same situation for the Tanner crab data, which we'll follow the same protocol with and then combine the data frames

```{r}
## RKC Data

# Read in data
cleaned_tidbit_data <- read_excel(path = "../data/ADFG_SE_AK_pot_surveys/Tidbits/2006/RKC_survey/skipper_tidbit_data.xls")

# Just to be safe, remove rows where the data point is from after the time hauled or 5 minutes after the pot was set (to allow it to fall to the bottom)
cleaned_tidbit_data <- cleaned_tidbit_data %>%
  filter(DateTime < TIME_HAULED & DateTime > (TIME_SET + 5))

# Each pot has a completely unique TIME_HAULED, so we can use that as the unique ID to average the temperatures over the pot's time in the water
cleaned_tidbit_data <- cleaned_tidbit_data %>%
  group_by(TIME_HAULED) %>%
  mutate(mean_temp = mean(`Temperature  (*C)`)) %>%
  ungroup

# Remove duplicate IDs for TIME_HAULED. This leaves us with one row per haul that includes average temp. We lose temp (as in specific measurement), date, time, and DateTime, but we don't care about that
cleaned_tidbit_data <- cleaned_tidbit_data[!duplicated(cleaned_tidbit_data$TIME_HAULED), ]

# TANNER CRAB DATA

# Read in data
new_cleaned_tidbit_data <- read_excel(path = "../data/ADFG_SE_AK_pot_surveys/Tidbits/2006/Tanner_survey/skipper_tidbit_data.xls")

# Just to be safe, remove rows where the data point is from after the time hauled or 5 minutes after the pot was set (to allow it to fall to the bottom)
new_cleaned_tidbit_data <- new_cleaned_tidbit_data %>%
  filter(Datetime < TIME_HAULED & Datetime > (TIME_SET + 5))

# We'll also remove any rows with an NA temperature, NA tidbit ID, or NA time hauled
new_cleaned_tidbit_data <- new_cleaned_tidbit_data %>%
  drop_na(c(`Temperature  (*C)`, `Tidbit #`, TIME_HAULED))

# Each pot has a completely unique TIME_HAULED, so we can use that as the unique ID to average the temperatures over the pot's time in the water
new_cleaned_tidbit_data <- new_cleaned_tidbit_data %>%
  group_by(TIME_HAULED) %>%
  mutate(mean_temp = mean(`Temperature  (*C)`)) %>%
  ungroup

# Remove duplicate IDs for TIME_HAULED. Now that we have avg temp, we just need one row. Plus, it's almost all identical anyways (except for temp, date, time, and DateTime).
new_cleaned_tidbit_data <- new_cleaned_tidbit_data[!duplicated(new_cleaned_tidbit_data$TIME_HAULED), ]

# Check if names match between data frames
all_equal(cleaned_tidbit_data, new_cleaned_tidbit_data, ignore_col_order = FALSE)

# Nope, we've got one extra column! Find it
new_cleaned_tidbit_data %>% select(which(!colnames(new_cleaned_tidbit_data) %in% colnames(cleaned_tidbit_data)))

cleaned_tidbit_data %>% select(which(!colnames(cleaned_tidbit_data) %in% colnames(new_cleaned_tidbit_data)))

# New data has Datetime, Set Date, and ID
# Old data has DateTime and Tidbit_NO.

# Change name of Datetime to DateTime
# Remove Set Date (info captured in TIME_SET)
# Remove ID (irrelevant)
# Remove Tidbit_NO. (already have a "Tidbit #" column)

# Change name of Datetime in new data
new_cleaned_tidbit_data <- rename(new_cleaned_tidbit_data, DateTime = Datetime)

# Drop columns from each dataset
new_cleaned_tidbit_data <- new_cleaned_tidbit_data %>%
  select(-c("Set Date", "ID"))

cleaned_tidbit_data <- cleaned_tidbit_data %>%
  select(-Tidbit_NO.)

# Merge two datasets
cleaned_tidbit_data <- rbind(cleaned_tidbit_data, new_cleaned_tidbit_data)
```


### 2007

2007 RKC is the same as 2006, already conveniently filtered and assembled! Just need to get the averages and do some slight cleaning.

2007 Tanners are not - instead, we'll just pull out the 

```{r}

```



