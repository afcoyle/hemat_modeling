geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape = 16) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape = 7) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape = 2) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape = 3) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape = 4) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape = 5) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape = 6) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape = 7) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape =87) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape =8) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, size = Depth), shape = 1) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, color = Depth), shape = 16) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, color = scale_color_viridis_c(depth)), shape = 16) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, color = scale_color_viridis_c(Depth)), shape = 16) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, color = Depth), shape = 16) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crab_latlong, aes(x = Longitude, y = Latitude, size = Latitude.length), shape = 16) +
scale_fill_continuous(type = "gradient") +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, color = Depth), shape = 16) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, color = Depth), shape = 16) +
scale_fill_continuous(type = "gradient") +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, color = Depth), shape = 16) +
scale_fill_continuous(type = "viridis") +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = crabdat, aes(x = Location, y = Depth)) +
geom_violin()
sum(crabdat$Location = "NS"
sum(crabdat$Location == "NS"
sum(crabdat$Location == "NS"
sum(crabdat$Location == "NS")
crabdat$s.Year <- crabdat$Year - (min(crabdat$Year) - 1)
crabdat <- read.csv("../output/NOAA_EBS_trawl_survey/modified_data/cleaned_bairdi.csv")
# First, since all crabs are C. bairdi, we can drop the Species column
crabdat <- subset(crabdat, select = -Species)
# See class of each column
str(crabdat)
# Looks like we've got lots of columns that should be converted to factors!
crabdat$Sex <- factor(crabdat$Sex)
crabdat$Shell_Condition <- ordered(crabdat$Shell_Condition)
crabdat$PCR_Result <- factor(crabdat$PCR_Result)
crabdat$Location <- factor(crabdat$Location)
# See updated class of each column
str(crabdat)
# Pull all numeric variables into a new data frame
crabnums <- select_if(crabdat, is.numeric)
# Calculate correlation
numcor <- cor(crabnums, method = "pearson")
# See the resulting table
print(numcor)
# See if any correlations are > 0.6 (our bar for correlation) and less than 1 (since every variable is perfectly correlated with itself)
any(abs(numcor) > 0.6 & numcor <1)
# See how many correlations we have (since each correlation is shown twice - A vs B and B vs A - the true number of correlations is 1/2 this number)
sum(abs(numcor) > 0.6 & numcor <1)
# Pull all categorical variables into a new data frame
crabcat <-  select_if(crabdat, is.factor)
# Turn all from factors to numeric
crabcat[] <- sapply(crabcat, as.numeric)
# Initialize a blank matrix
results_matrix <- matrix(nrow = length(crabcat), ncol = length(crabcat))
# Name all rows and columns with our variable names
colnames(results_matrix) <- names(crabcat)
rownames(results_matrix) <- names(crabcat)
# Fill in the matrix by performing Cramer's V test on each possible combination of factors
for (i in 1:ncol(crabcat)) {
for (j in 1:ncol(crabcat)) {
cramer.table <- table(crabcat[,i],crabcat[,j])
cramer.matrix <- as.matrix(cramer.table)
results_matrix[i,j] <- cramerV(cramer.matrix)
}
}
# See the resulting matrix
print(results_matrix)
# See if any of our correlations, aside from self-correlations, cross our boundary of too much correlation
any(abs(results_matrix) > 0.6 & results_matrix < 1)
# Looks like we have no correlation between categorical variables!
crabrank <- crabdat
crabrank[] <- sapply(crabdat, as.numeric)
crabcomps <- cor(crabrank, method = "spearman")
any(abs(crabcomps) > 0.6 & crabcomps < 1)
linkages <- which(abs(crabcomps) > 0.6 & crabcomps < 1, arr.ind = TRUE)
# List linkages
for (i in 1:(0.5*length(linkages))) {
print(names(crabdat)[c(linkages[i,])])
}
print(0.5*length(linkages))
ggplot(crabdat, aes(x = Shell_Condition, y = Carapace_Width)) +
geom_violin()
crab_latlong <- summaryBy(crabdat~Latitude + Longitude, data = crabdat, FUN = length)
world <- ne_countries(scale = "medium", returnclass = "sf")
ggplot(data = world) +
geom_sf() +
geom_point(data = crab_latlong, aes(x = Longitude, y = Latitude, size = Latitude.length), shape = 16) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, color = Depth), shape = 16) +
scale_fill_continuous(type = "viridis") +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
crabdat$s.Year <- crabdat$Year - (min(crabdat$Year) - 1)
# Scale all other continuous variables
class(crabdat)
# Scale all other continuous variables
str(crabdat)
# Scale all other continuous variables
crabdat <- CW_scaled <- scale(crabdat$Carapace_Width)
str(crabdat)
str(crabdat)
crabdat <- read.csv("../output/NOAA_EBS_trawl_survey/modified_data/cleaned_bairdi.csv")
# First, since all crabs are C. bairdi, we can drop the Species column
crabdat <- subset(crabdat, select = -Species)
# See class of each column
str(crabdat)
# Looks like we've got lots of columns that should be converted to factors!
crabdat$Sex <- factor(crabdat$Sex)
crabdat$Shell_Condition <- ordered(crabdat$Shell_Condition)
crabdat$PCR_Result <- factor(crabdat$PCR_Result)
crabdat$Location <- factor(crabdat$Location)
# See updated class of each column
str(crabdat)
# Pull all numeric variables into a new data frame
crabnums <- select_if(crabdat, is.numeric)
# Calculate correlation
numcor <- cor(crabnums, method = "pearson")
# See the resulting table
print(numcor)
# See if any correlations are > 0.6 (our bar for correlation) and less than 1 (since every variable is perfectly correlated with itself)
any(abs(numcor) > 0.6 & numcor <1)
# See how many correlations we have (since each correlation is shown twice - A vs B and B vs A - the true number of correlations is 1/2 this number)
sum(abs(numcor) > 0.6 & numcor <1)
# Pull all categorical variables into a new data frame
crabcat <-  select_if(crabdat, is.factor)
# Turn all from factors to numeric
crabcat[] <- sapply(crabcat, as.numeric)
# Initialize a blank matrix
results_matrix <- matrix(nrow = length(crabcat), ncol = length(crabcat))
# Name all rows and columns with our variable names
colnames(results_matrix) <- names(crabcat)
rownames(results_matrix) <- names(crabcat)
# Fill in the matrix by performing Cramer's V test on each possible combination of factors
for (i in 1:ncol(crabcat)) {
for (j in 1:ncol(crabcat)) {
cramer.table <- table(crabcat[,i],crabcat[,j])
cramer.matrix <- as.matrix(cramer.table)
results_matrix[i,j] <- cramerV(cramer.matrix)
}
}
# See the resulting matrix
print(results_matrix)
# See if any of our correlations, aside from self-correlations, cross our boundary of too much correlation
any(abs(results_matrix) > 0.6 & results_matrix < 1)
# Looks like we have no correlation between categorical variables!
crabrank <- crabdat
crabrank[] <- sapply(crabdat, as.numeric)
crabcomps <- cor(crabrank, method = "spearman")
any(abs(crabcomps) > 0.6 & crabcomps < 1)
linkages <- which(abs(crabcomps) > 0.6 & crabcomps < 1, arr.ind = TRUE)
# List linkages
for (i in 1:(0.5*length(linkages))) {
print(names(crabdat)[c(linkages[i,])])
}
print(0.5*length(linkages))
ggplot(crabdat, aes(x = Shell_Condition, y = Carapace_Width)) +
geom_violin()
crab_latlong <- summaryBy(crabdat~Latitude + Longitude, data = crabdat, FUN = length)
world <- ne_countries(scale = "medium", returnclass = "sf")
ggplot(data = world) +
geom_sf() +
geom_point(data = crab_latlong, aes(x = Longitude, y = Latitude, size = Latitude.length), shape = 16) +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = world) +
geom_sf() +
geom_point(data = crabdat, aes(x = Longitude, y = Latitude, color = Depth), shape = 16) +
scale_fill_continuous(type = "viridis") +
coord_sf(xlim = c(-180, -160), ylim = c(50, 70), expand = FALSE)
ggplot(data = crabdat, aes(x = Location, y = Depth)) +
geom_violin()
# Subtract the year before the earliest data, so year now starts at 1
crabdat$s.Year <- crabdat$Year - (min(crabdat$Year) - 1)
# Scale all other continuous variables
crabdat$CW_scaled <- scale(crabdat$Carapace_Width)
str(crabdat)
crabdat$Latitude_scaled <- scale(crabdat$Latitude)
crabdat$Longitude_scaled <- scale(crabdat$Longitude)
crabdat$Depth_scaled <- scale(crabdat$Depth)
str(crabdat)
crabdat <- subset(crabdat, select = -Julian_Day)
str(crabdat)
crabdat$Bottom_Temp_scaled <- scale(crabdat$Bottom_Temp)
str(crabdat)
test_mod <- glmer(PCR_Result ~ CW_scaled + Latitude_scaled + Longitude_scaled + Bottom_Temp_scaled + Sex + Shell_Condition + (1 | s.Year),
data = crabdat,
family = binomial,
na.action = "na.fail", # this chunk is for dredge()
control = glmerControl(optimizer = c("bobyqa")))
dredge(test_mod)
View(test_mod)
summary(test_mod)
latlong_mod <- glmer(PCR_Result ~ CW_scaled + Latitude_scaled + Longitude_scaled + Bottom_Temp_scaled + Sex + Shell_Condition + (1 | s.Year),
data = crabdat,
family = binomial,
na.action = "na.fail", # this chunk is for dredge()
control = glmerControl(optimizer = c("bobyqa")))
long_mod1 <- glmer(PCR_Result ~ CW_scaled +  Longitude_scaled + Bottom_Temp_scaled + Sex + Shell_Condition + (1 | s.Year),
data = crabdat,
family = binomial,
na.action = "na.fail", # this chunk is for dredge()
control = glmerControl(optimizer = c("bobyqa")))
latlong_mod2 <- glmer(PCR_Result ~ CW_scaled +  Longitude_scaled + Latitude_scaled + Bottom_Temp_scaled + Sex + Shell_Condition + (1 | s.Year),
data = crabdat,
family = binomial,
na.action = "na.fail", # this chunk is for dredge()
control = glmerControl(optimizer = c("bobyqa")))
loc_mod3 <- glmer(PCR_Result ~ CW_scaled + Bottom_Temp_scaled + Sex + Shell_Condition + (1 | s.Year) + (1 | Location),
data = crabdat,
family = binomial,
na.action = "na.fail", # this chunk is for dredge()
control = glmerControl(optimizer = c("bobyqa")))
depth_mod4 <- glmer(PCR_Result ~ CW_scaled + Depth_scaled + Bottom_Temp_scaled + Sex + Shell_Condition + (1 | s.Year),
data = crabdat,
family = binomial,
na.action = "na.fail", # this chunk is for dredge()
control = glmerControl(optimizer = c("bobyqa")))
extractAIC(long_mod1)
extractAIC(latlong_mod2)
extractAIC(loc_mod3)
extractAIC(depth_mod4)
extractAIC(long_mod1)
extractAIC(latlong_mod2)
extractAIC(loc_mod3)
extractAIC(depth_mod4)
lap_mods <- dredge(depth_mod4, beta = "none",
eval = TRUE,
rank = "AICc")
lap_mods
# Get all models with weights above 0.01
best_models <- get.models(lap_mods, subset = weight > 0.01)
# Look at first model
summary(best_models[[1]])
summary(best_models[[2]])
best_models
lap_mods
# Look at second model (weight = 0.21)
summary(best_models[[2]])
lap_mods
# Look at third model (weight = 0.14)
summary(best_models[[3]])
avg_model <- model.avg(best_models, beta = "none")
# See what the average model looks like
avg_model$coefficients
summary(avg_model)
View(crab_latlong)
knitr::opts_chunk$set(echo = TRUE)
crabdat <- read.csv(file = "../data/ADFG_SE_AK_pot_surveys/TC_survey_specimen_data_all_years.csv")
View(crabdat)
colnames(crabdat)
# Add all required libraries here
list.of.packages <- c("tidyverse", "readxl", "lubridate", "rnaturalearth", "rnaturalearthdata", "sf", "rgeos")
# Get names of all required packages that aren't installed
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
# Install all new packages
if(length(new.packages)) install.packages(new.packages)
# Load all required libraries
lapply(list.of.packages, FUN = function(X) {
do.call("require", list(X))
})
test <- crabdat %>%
rename(year = "ï..Year")
View(test)
crabdat <- crabdat %>%
rename(Year = "ï..Year")
View(crabdat)
View(crabdat)
colnames(crabdat)
table(crabdat$Specimen.No)
table(crabdat$Recruit.Status)
test <- crabdat %>%
select(-c(Specimen.No, Number.Of.Specimens, Length.Millimeters,
Width.Spines.Millimeters, Specimen.Comments, Tag.No,
Tag.Event.Code))
crabdat <- crabdat %>%
select(-c(Specimen.No, Number.Of.Specimens, Length.Millimeters,
Width.Spines.Millimeters, Specimen.Comments, Tag.No,
Tag.Event.Code))
View(crabdat)
table(crabdat$Parasite)
table(crabdat$Year)
ggplot(data = table(crabdat)) +
geom_line()
plot(table(crabdat$Year))
# Now look at this in table form
table(crabdat$Year)
# First variable - year
plot(table(crabdat$Year))
colnames(crabdat)
table(crabdat$Project)
# Unsurprisingly, we have data from both the RKC and Tanner surveys. Interestingly, a lot more Tanners have been measured on the RKC surveys. Let's look at how this changes over time
plot(table(crabdat$Year, crabdat$Project))
# Unsurprisingly, we have data from both the RKC and Tanner surveys. Interestingly, a lot more Tanners have been measured on the RKC surveys. Let's look at how this changes over time
ggplot(as.data.frame(table(crabdat$Year, crabdat$Project)),
aes(x = Year, fill = Project)) +
geom_bar(stat = "identity")
as.data.frame(table(crabdat$Year, crabdat$Project))
# Unsurprisingly, we have data from both the RKC and Tanner surveys. Interestingly, a lot more Tanners have been measured on the RKC surveys. Let's look at how this changes over time
ggplot(as.data.frame(table(crabdat$Year, crabdat$Project)),
aes(x = Var2, fill = Freq)) +
geom_bar(stat = "identity")
as.data.frame(table(crabdat$Year, crabdat$Project))
# Unsurprisingly, we have data from both the RKC and Tanner surveys. Interestingly, a lot more Tanners have been measured on the RKC surveys. Let's look at how this changes over time
ggplot(as.data.frame(table(crabdat$Year, crabdat$Project)),
aes(x = Var1, y = Var2)) +
geom_bar(stat = "identity")
# Unsurprisingly, we have data from both the RKC and Tanner surveys. Interestingly, a lot more Tanners have been measured on the RKC surveys. Let's look at how this changes over time
ggplot(as.data.frame(table(crabdat$Year, crabdat$Project)),
aes(x = Var1, y = Freq, fill = Var2)) +
geom_bar(stat = "identity")
# Looking at Project column
table(crabdat$Project)
# Interesting - so initially, all Tanner crabs caught were on the RKC survey, and the Tanner crab survey is newer.
# Let's see the first survey that included Tanner crabs
as.data.frame(table(crabdat$Year, crabdat$Project == "Tanner Crab Survey"))
?min
# Interesting - so initially, all Tanner crabs caught were on the RKC survey, and the Tanner crab survey is newer.
# Let's see the first survey that included Tanner crabs
as.data.frame(table(crabdat$Year, crabdat$Project == "Tanner Crab Survey"))$Var2 == TRUE
min <- crabdat %>%
group_by(Project) %>%
filter(estimate == min(Year))
min <- crabdat %>%
group_by(Project) %>%
filter(year == min(Year))
min <- crabdat %>%
group_by(Project
min
min <- crabdat %>%
group_by(Project)
View(min)
?top_n
min <- crabdat %>%
group_by(Project) %>%
slice_min(Year)
View(min)
View(min)
?min
crabdat[crabdat$Project == "Tanner Crab Survey", 1]
crabdat[crabdat$Project == "Tanner Crab Survey", 'Year']
min(crabdat[crabdat$Project == "Tanner Crab Survey", 'Year'])
crabdat$Trip.No
table(crabdat$Trip.No)
test <- crabdat %>%
na.if(crabdat$Trip.No, 999)
# Add all required libraries here
list.of.packages <- c("tidyverse", "readxl", "lubridate", "rnaturalearth", "rnaturalearthdata", "sf", "rgeos")
# Get names of all required packages that aren't installed
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
# Install all new packages
if(length(new.packages)) install.packages(new.packages)
# Load all required libraries
lapply(list.of.packages, FUN = function(X) {
do.call("require", list(X))
})
test <- crabdat %>%
na.if(crabdat$Trip.No, 999)
test <- crabdat %>%
na_if(crabdat$Trip.No, 999)
test <- crabdat %>%
na_if(crabdat$Trip.No, 999)
?na_if
test <- crabdat %>%
select(Trip.No) %>%
mutate(Trip.No = na_if(Trip.No, 999))
table(crabdat$Trip.No)
table(test$Trip.No)
crabdat <- crabdat %>%
select(Trip.No) %>%
mutate(Trip.No = na_if(Trip.No,))
test <- crabdat %>%
select(Trip.No) %>%
mutate(Trip.No = na_if(Trip.No,))
test2 <- crabdat %>%
select(Trip.No) %>%
mutate(Trip.No = na_if(Trip.No,))
test <- crabdat %>%
select(Trip.No) %>%
mutate(Trip.No = na_if(Trip.No,))
table(crabdat$Trip.No)
test <- crabdat %>%
select(Trip.No) %>%
mutate(Trip.No = na_if(Trip.No,))
test <- crabdat %>%
select(Trip.No) %>%
mutate(Trip.No = na_if(Trip.No, 999))
table(crabdat$Trip.No)
crabdat <- crabdat %>%
select(Trip.No) %>%
mutate(Trip.No = na_if(Trip.No, 999))
table(crabdat$Trip.No)
# Verify we did it correctly
table(crabdat$Trip.No)
?table
# Looks like there were no surveys carried out in 1990 or 1992! Let's confirm this by looking at this in table form
table(crabdat$Year, useNA = "always")
# Looks like there were no surveys carried out in 1990 or 1992! Let's confirm this by looking at this in table form
table(crabdat$Year, useNA = "ifany")
# Looks like there were no surveys carried out in 1990 or 1992! Let's confirm this by looking at this in table form
table(crabdat$Year, useNA = "ifany")
# Looks like there were no surveys carried out in 1990 or 1992! Let's confirm this by looking at this in table form
table(crabdat$Year)
View(crabdat)
crabdat <- read.csv(file = "../data/ADFG_SE_AK_pot_surveys/TC_survey_specimen_data_all_years.csv")
colnames(crabdat)
crabdat <- crabdat %>%
rename(Year = "ï..Year")
# We can start by removing several columns.
# Project, Trip Number, and Pot Number are likely to be useful in the future to match skipper data to survey data.
# However, we can remove the following columns:
# Specimen.No: We don't particularly care about this - it seems to be its spot on the page
# Number.Of.Specimens: Indicates the degree of subsampling, which we also don't care about
# Length.Millimeters: Tanner crab size is measured via width, not length (king crabs, which were kept in the same database, are measured with length)
# Width.Spines.Millimeters: Also not used for Tanner crab size, column likely only for Dungeness crabs
# Specimen.Comments: Don't care about comments of individual crab. Plus this is 40+ years of data, comments are way too varied to make any real sense of
# Tag.No: Crab number of each crab is irrelevant
# Tag.Event.Code: Event under which each crab was tagged is irrelevant
crabdat <- crabdat %>%
select(-c(Specimen.No, Number.Of.Specimens, Length.Millimeters,
Width.Spines.Millimeters, Specimen.Comments, Tag.No,
Tag.Event.Code))
# First variable - year
plot(table(crabdat$Year))
# Looks like there were no surveys carried out in 1990 or 1992! Let's confirm this by looking at this in table form
table(crabdat$Year)
# Looking at Project column
table(crabdat$Project)
# Unsurprisingly, we have data from both the RKC and Tanner surveys. Interestingly, a lot more Tanners have been measured on the RKC surveys. Let's look at how this changes over time
ggplot(as.data.frame(table(crabdat$Year, crabdat$Project)),
aes(x = Var1, y = Freq, fill = Var2)) +
geom_bar(stat = "identity")
# Interesting - so initially, all Tanner crabs caught were on the RKC survey, and the Tanner crab survey is newer.
# Let's see the first survey that included Tanner crabs
min(crabdat[crabdat$Project == "Tanner Crab Survey", 'Year'])
table(crabdat$Trip.No)
# Looks like surveys were a maximum of 3 legs, with 1 error code (999). Let's change that 999 to an NA
crabdat <- crabdat %>%
mutate(Trip.No = na_if(Trip.No, 999))
# Verify we did it correctly
table(crabdat$Trip.No)
View(crabdat)
# Verify we did it correctly
table(crabdat$Trip.No, useNA = "ifany")
table(crabdat$Trip.No, useNA = "ifany")
# Looking at Project column
table(crabdat$ProjectuseNA = "ifany")
# Looking at Project column
table(crabdat$Project, useNA = "ifany")
knitr::opts_chunk$set(echo = TRUE)
crabdat <- read.csv("../output/NOAA_EBS_trawl_survey/modified_data/cleaned_bairdi.csv")
View(crabdat)
knitr::opts_chunk$set(echo = TRUE)
crabdat <- read.csv(file = "../data/ADFG_SE_AK_pot_surveys/TC_survey_specimen_data_all_years.csv")
View(crabdat)
