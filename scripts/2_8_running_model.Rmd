---
title: "2_8_running_model"
author: "Aidan Coyle"
date: "8/12/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background

In this script, we will create a generalized linear mixed model to examine potential associations between _Hematodinium_ infection status and variables within both the environment and the crab.

This script will include both male and female crab, and only include crabs for which temperature data is available.


#### Load libraries (and install if necessary)

```{r libraries, message=FALSE, warning=FALSE}
# Add all required libraries here
list.of.packages <- c("tidyverse", "lme4", "MuMIn", "rcompanion", "MASS", "generalhoslem", "mgcv", "beepr", "regclass", "car", "DHARMa", "broom.mixed", "dotwhisker", "glmmTMB", "performance", "effects")
# Get names of all required packages that aren't installed
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
# Install all new packages
if(length(new.packages)) install.packages(new.packages)


# Load all required libraries
lapply(list.of.packages, FUN = function(X) {
  do.call("require", list(X))
})

# Read in custom functions
source("hemat_modeling_functions.R")

```

# Read in data
```{r}
crab_dat <- read.csv(file = "../output/ADFG_SE_AK_pot_surveys/cleaned_data/crab_data/BCS_examined_crab_with_temperature.csv")
```

### Check all variables were read in correctly as either categorical or continuous predictors

```{r}
# See class of each column
str(crab_dat)
# Looks like we've got lots of columns that should be converted to factors!
crab_dat$Survey <- factor(crab_dat$Survey)
crab_dat$Site <- factor(crab_dat$Site)
crab_dat$Sex <- factor(crab_dat$Sex)
crab_dat$Recruit.Status <- factor(crab_dat$Recruit.Status)
crab_dat$Shell.Condition <- ordered(crab_dat$Shell.Condition)
crab_dat$Egg.Condition <- factor(crab_dat$Egg.Condition)
crab_dat$Egg.Development <- factor(crab_dat$Egg.Development)
crab_dat$Leg.Condition <- factor(crab_dat$Leg.Condition)
crab_dat$Bitter <- factor(crab_dat$Bitter)
crab_dat$Blackmat <- factor(crab_dat$Blackmat)

# See updated class of each column
str(crab_dat)
```

### Check for correlation

Prior to modeling anything, we're going to run checks on combinations of variables to see if any are correlated

```{r}
# CORRELATION BETWEEN CONTINUOUS VARIABLES

crab_nums <- select_if(crab_dat, is.numeric)
numcor <- cor(crab_nums, method = "pearson")

# See the resulting table
print(numcor)

# See if any correlations are > 0.6 (our bar for correlation) and less than 1 (since every variable is perfectly correlated with itself)
any(abs(numcor) > 0.6 & numcor < 1)
which(abs(numcor) > 0.6 & numcor < 1, arr.ind = TRUE)
# Looks like we have a tight correlation between latitude and longitude
# Temperature and Julian day are pretty close (corr = 0.56), but nothing else is above 0.5

# CORRELATIONS BETWEEN CATEGORICAL VARIABLES

# Now we're using Cramer's V test to look at correlation among our categorical variables
crabcat <- select_if(crab_dat, is.factor)

# Turn all from factors to numeric
crabcat[] <- sapply(crabcat, as.numeric)

# Initialize a blank matrix
results_matrix <- matrix(nrow = length(crabcat), ncol = length(crabcat))
# Name all rows and columns with our variable names
colnames(results_matrix) <- names(crabcat)
rownames(results_matrix) <- names(crabcat)

# Fill the matrix by performing Cramer's V test on each possible combination of factors
for (i in 1:ncol(crabcat)) {
  for (j in 1:ncol(crabcat)) {
    cramer.table <- table(crabcat[,i],crabcat[,j])
    cramer.matrix <- as.matrix(cramer.table)
    results_matrix[i,j] <- cramerV(cramer.matrix)
  }
}
# See the resulting matrix
print(results_matrix)

# See if any of our correlations (aside from self-correlations) cross our boundary of too much correlation
any(results_matrix > 0.6 & results_matrix < 1)
which(abs(results_matrix) > 0.6 & results_matrix < 1, arr.ind = TRUE)

# Tight correlation between survey and site, which is fine - we weren't planning to include survey in any model
# Correlations of 1 between recruit status and sex too, indicating we should choose one for our models
#       We'll pick sex, since recruit status is mostly captured by sex + CW
# No other strong correlations

# CORRELATIONS BETWEEN CATEGORICAL AND CONTINUOUS VARIABLES

# We'll use Spearman rank-order correlation to determine whether we have any correlation
crabrank <- crab_dat
crabrank[] <- sapply(crab_dat, as.numeric)
crabcomps <- cor(crabrank, method = "spearman")
any(abs(crabcomps) > 0.6 & crabcomps < 1)
# Looks like we do have some significant correlations this time! Let's pull them out
which(abs(crabcomps) > 0.6 & crabcomps < 1, arr.ind = TRUE)
print(crabcomps)
# Correlations are between:
    # Julian day and survey (don't care, not including survey in model)
    # Recruit status and CW (already decided to exclude recruit status from model since it's mostly CW + sex)
    # Latitude and longitude (we'll likely just use latitude, or skip altogether and just use site)
    # Temperature and Julian day (these are two continuous variables, which were already cleared using the more appropriate Pearson metric)
```



# Adjust numeric variables, scaling some

```{r}
# Subtract 2004 from all years, so that our earliest year is 1
crab_dat$s.Year <- crab_dat$Year-(min(crab_dat$Year)-1)

# Scale chela height, egg percent, latitude, longitude, Julian day, depth, and temperature
crab_dat$s.Chela.Ht <- scale(crab_dat$Chela.Ht)
crab_dat$s.Egg.Percent <- scale(crab_dat$Egg.Percent)
crab_dat$s.Latitude <- scale(crab_dat$Latitude)
crab_dat$s.Longitude <- scale(crab_dat$Longitude)
crab_dat$s.Jul.Day <- scale(crab_dat$Jul.Day)
crab_dat$s.Depth <- scale(crab_dat$Depth)
crab_dat$s.Temp <- scale(crab_dat$Temp)

# We'll scale CW twice - once for males, and once for females. This'll capture the sexual dimorphism within Tanner crabs
crab_dat_f <- crab_dat[crab_dat$Sex == "2", ]
crab_dat_m <- crab_dat[crab_dat$Sex == "1", ]

crab_dat_f$s.CW <- scale(crab_dat_f$CW)
crab_dat_m$s.CW <- scale(crab_dat_m$CW)

crab_dat <- rbind(crab_dat_f, crab_dat_m)
```

# MODEL OF ALL CRABS

This model will include ALL crabs, both male and female. Therefore, it will not include sex-specific measurements, such as chela height and egg-related measurements

We have a Bernoulli distribution (binomial), plus random effects of year and location


```{r}
# Select all variables to be used in our model for all crabs
allcrabs_dat <- crab_dat %>%
  dplyr::select(c(s.Year, Site, Sex, s.CW, Shell.Condition, Leg.Condition, Bitter, Blackmat, s.Latitude, s.Jul.Day, s.Depth, s.Temp))

# Select independent variables
modeled_vars <- names(allcrabs_dat)
modeled_vars <- modeled_vars[!modeled_vars %in% c("s.Year", "Site", "Bitter")]

# Initialize dataframe with model values
AIC_vals <- matrix(nrow = length(modeled_vars), ncol = 2)

# Create a null model and get AIC
null_mod <- glmer(Bitter ~ (1 | Site) + (1 | s.Year), 
                  data = allcrabs_dat,
                  family = binomial)
AIC_null <- extractAIC(null_mod)[2]
AIC_vals[1, 1] <- "null_mod"
AIC_vals[1, 2] <- extractAIC(null_mod)[2] - AIC_null

# Create for loop to extract AIC for all variables
for (i in 1:length(modeled_vars)){
  my_formula = paste0("Bitter ~ ", modeled_vars[i], " + (1 | Site) + (1 | s.Year)")
  test_mod <- glmer(my_formula,
                    data = allcrabs_dat,
                    family = binomial)
  
  AIC_vals[i, 1] <- modeled_vars[i]
  AIC_vals[i, 2] <- extractAIC(test_mod)[2] - AIC_null
}
beep()


# See which variables improve the model the most
# I just printed these and reordered them around a bit
AIC_vals[order(as.numeric(AIC_vals[, 2])), ]
```

Here's the order of the impact of our variables, from most to least impactful. 

Shell condition
Temperature
CW
Black Mat
Leg condition
Julian day
Sex
---------Null model line ------------------
Latitude
Depth

### Build model

```{r}
full_model <- glmmTMB(Bitter ~ Shell.Condition + s.Temp + s.CW + Blackmat + Leg.Condition + s.Jul.Day + Sex + s.Latitude + s.Depth + (1 | Site) + (1 | s.Year),
                       data = allcrabs_dat,
                       family = binomial,
                       na.action = "na.fail")              # This line is for the dredge() function used later
                       

check_collinearity(full_model)

# Alright, VIFs look good!

```


### Model Diagnostics

Now that we have produced a full model, before we start fine-tuning it, we need to do some diagnostics to ensure it meets our assumptions

```{r}
# Simulate residuals and plot
testOutliers(full_model, alternative = "two.sided", margin = "both", type = "bootstrap", plot = TRUE)
simulateResiduals(full_model, plot = TRUE)

# Perform ANOVA on model fits
car::Anova(full_model)

# Alright, looks like in our full model, everything is significant except leg condition and depth (with latitude being barely significant)

# Test for effects. You can plot these all together with plot(allEffects(full_model)), but that gets crowded visually
plot(predictorEffect("Shell.Condition", full_model))
plot(predictorEffect("s.Temp", full_model))
plot(predictorEffect("s.CW", full_model))
plot(predictorEffect("Blackmat", full_model))
plot(predictorEffect("Leg.Condition", full_model))
plot(predictorEffect("s.Jul.Day", full_model))
plot(predictorEffect("Sex", full_model))
plot(predictorEffect("s.Latitude", full_model))
plot(predictorEffect("s.Depth", full_model))
```
### Dredging

We will now use the dredge() function from the MuMIn package to go through each of our model possibilities and select an optimal full model using AICc.

```{r}
all_mods <- dredge(full_model, beta = "none",
       eval = TRUE,
       rank = "AICc")

plot(all_mods)

# Looks like we have four good models (weights > 0.2) and four marginal models (weights between 0.04 and 0.01)
best_mods <- get.models(all_mods, subset = weight > 0.01)

all_best_mod <- get.models(all_mods, subset = 1)[[1]]

# See what each of the best models look like
best_mods[1]
best_mods[2] # Same as #1, but drops Depth
best_mods[3] # Same as #1, but includes Leg Condition
best_mods[4] # Same as #1, but includes Leg Condition and drops Depth
best_mods[5] # Same as #1, but drops Latitude
best_mods[6] # Same as #1, but includes Leg Condition and drops Latitude
best_mods[7] # Same as #1, but drops Depth and Latitude
best_mods[8] # Same as #1, but includes Leg Condition and drops Depth + Latitude

# Average models based on AICc
avg_model <- model.avg(best_mods, beta = "none")

# See what that average model looks like
avg_model$coefficients
summary(avg_model)
```
### More tests 
```{r}
#### Test dispersion of each of our eight best models

# Note: they're all going to fail the KS test, just because our sample size is huge. As long as the QQ plot looks fine, no cause for concern.


# First model
simulationOutput <- simulateResiduals(fittedModel = best_mods[1][[1]], plot = F) 

plot(simulationOutput, asFactor = TRUE)


testDispersion(best_mods[1][[1]])       # Looks good! P-value = 0.73, residuals look evenish



```


```{r}



#Evaluate Error Assumptions########################################################

## Testing the assumption of "identically distributed" 

#plot residuals against fitted
plot(fitted(all_best_mod),residuals(all_best_mod))
abline(h = 0)

#plot sqrt(abs(residuals)) against fitted
plot(fitted(lmod), sqrt(abs(residuals(lmod))))

#regress sqrt(abs(error)) on fitted
summary(lmod.test <- lm(sqrt(abs(residuals(lmod))) ~ fitted(lmod)) )

#use an F-test to test "big" residuals against small residuals to see if they come from the same distribution
ee <- residuals(lmod)
g1 <- ee[ee < median(ee)]
g2 <- ee[ee > median(ee)]
var.test(g1, g2)

#Another version of this is Levene's Test, which is robust to non-normality
#in this case, they give you nearly the same result 
KW$group <- rep(0,nrow(KW))
KW$group[which(residuals(lmod)>median(residuals(lmod)))] <- 1
KW$group <- as.factor(KW$group)
leveneTest(residuals(lmod),KW$group)

#Faraway demonstrates Levene's test as follows in the book - notice the answer is the same as for `leveneTest`
med <- with(KW,tapply(ee,group,median))
ar <- with(KW,abs(ee -med[group]))
anova(lm(ar ~ group,KW))


## Testing the assumption of "normally distributed" 

#produce a qqplot 
qqnorm(residuals(lmod))
qqline(residuals(lmod))

#it's a good idea to get a sense of what a "good" QQ plot with your n might look like
eps <- rnorm(nrow(KW),mean=0,sd=sqrt(sigma2))
qqnorm(eps)
qqline(eps)

#make a QQ plot of standardized residuals - can be easier to look at 
qqnorm(rstandard(lmod))
qqline(rstandard(lmod))

## Testing the assumption of "independently distributed" 

#Here we have temporal data so we might want to plot residual(t+1) against residual(t)
plot(head(residuals(lmod),n-1),tail(residuals(lmod),n-1),xlab = expression(epsilon(t)),ylab = expression(epsilon(t+1)))


#Unusual Observations########################################################

#look for any large leverage points 
hatv <- hatvalues(lmod)
sort(hatv)
(two_p_over_n <- 2*2/n )

#create a half normal plot of leverages
require(faraway)
yrs <- KW$years
halfnorm(hatv,nlab = 3, labs= yrs, ylab="Leverages")

#get studentized residuals 
studentized <- rstudent(lmod)
(max.student <- studentized[which.max(abs(studentized))] )
#this is the quantile that your studentized residual must exceed to be significant at 0.05 (note 2-sided test) 
#note that this includes a Bonferonni correction (we adjust our p-value)
qt(0.025/n,n-2-1,lower.tail = FALSE)
#you can also get this here  
library(car)
outlierTest(lmod)

#calculate the cooks.distance for any potentially influential points 
cook <- cooks.distance(lmod)
halfnorm(cook,3,labs=row.names(KW),ylab="Cook's distances")
#exclude point with largest Cook's distance - does it change model fit 
lmod2 <- lm(prcnt ~ years, KW, subset = (years != 20))
#plot all - the point with largest Cook's distance didn't make much difference to fit
plot(KW$years, KW$prcnt)
abline(lmod)
abline(lmod2, lty = 2)



#Generalized Least Squares########################################################

#Because our data are time data, we might want to look for any temporal autocorrelation in errors
acf(KW$prcnt)
acf(residuals(lmod))

#eps[t] ~ N(phi*eps[t-1], tau)
lmod1.gls <- gls(prcnt ~ years,
              correlation = corAR1(form = ~ years),
              data = na.omit(KW))
summary(lmod1.gls)
#look at the intervals on correlation 
intervals(lmod1.gls)


#Let's also look at the global warming data from Faraway
data(globwarm, package = "faraway")
#trim to recent years
dat <- globwarm[globwarm$year > 1960,]

#Plot data
plot(dat$nhtemp, dat$wusa, xlab = "Temperature", ylab = "Tree growth", main = "")

#Let's fit a simple regression model where tree growth (`wusa`) is a function of temperature (`nhtemp`).
model2 <- lm(wusa ~ nhtemp, dat)

res <- residuals(model2)

#Plot fitted against residuals
plot(fitted(model2), res, xlab = "Fitted values", ylab = "Residuals", main = "")
abline(h = 0, lty ="dashed")
plot(res[1:(length(res)-1)], res[2:length(res)], xlab = expression(italic(e[t])), ylab = expression(italic(e)[italic(t)+1]),
     main = "")

#We can also try the acf plot here 
acf(ee,ylab = expression(paste("Correlation of ", italic(e[t]), " & ", italic(e[t + h]))),main = "")

#Let's try a generalized least squares fit 
model3 <- gls(nhtemp ~ wusa,
             correlation = corAR1(form = ~ year),
             data = na.omit(globwarm))

#The model here is y[t] = X[t]B + eps[t], eps[t] ~ N(phi*(eps[t-1]),sigma) 

## examine parameters - notice our correlation is pretty high
summary(model3)
intervals(model3)



#Box-Cox Transformations########################################################

#let's see whether the Box-Cox transformation indicates that we should try a transformation
require(MASS)
bc <- boxcox(lmod,plotit=TRUE,lambda = seq(-2,3,by = 0.1))
bc$x[which.max(bc$y)]

#this looks good but we will fit a square root transformation to see how it works 
summary( lmod.trans <- lm(sqrt(prcnt) ~ years, KW) )

#plot error against fitted
plot(fitted(lmod.trans),residuals(lmod.trans))
abline(h = 0)

#predict and plot on the transformed response 
plot(sqrt(prcnt) ~ years, cex.lab = 1.5, cex.axis = 1.5, ylab = expression(sqrt(Prcnt)), xlab = "Years")
abline(lmod.trans)

#get a confidence interval 
out <- predict(lmod.trans, newdata = data.frame(x = years), interval="confidence")

#now plot on the real scale with the confidence interval
plot(prcnt ~ years, cex.lab = 1.5, cex.axis = 1.5, ylab = "Prcnt", xlab = "Years")
lines(years,out[,1]^2,col="red")
lines(years,out[,2]^2,lty = 2,col="red")
lines(years,out[,3]^2,lty = 2,col="red")

#now the the prediction interval, also on the real scale 
out2 <- predict(lmod.trans, newdata = data.frame(x = years), interval="prediction")
lines(years,out2[,1]^2,col="blue")
lines(years,out2[,2]^2,lty = 2,col="blue")
lines(years,out2[,3]^2,lty = 2,col="blue")
```


# MODEL OF FEMALE CRABS

This model will include all female crabs with egg-related measurements

### Filter and re-scale to get correct data for model

```{r}
# Select only female crabs
fem_crabs <- crab_dat %>%
  filter(Sex == "2")

# Drop chela height column
fem_crabs <- fem_crabs %>%
  dplyr::select(-Chela.Ht)

# Drop scaled columns - we'll scale them again
fem_crabs <- fem_crabs %>%
  dplyr::select(-contains("s."))

# We'll try to move Egg Development and Egg Condition into a single column, a lot of the data is redundant or useless

# We likely should have just done this in script 2_7, but hey, no time like the present (and I don't want to go back and potentially have to re-run my all crabs model)

# Move barren clean/matted data into the Egg Development column
fem_crabs <- fem_crabs %>%
  mutate(Egg.Development = ifelse(Egg.Condition == "Barren_Clean", "Barren_Clean", as.character(Egg.Development)))
fem_crabs <- fem_crabs %>%
  mutate(Egg.Development = ifelse(Egg.Condition == "Barren_Matted", "Barren_Matted", as.character(Egg.Development)))

# Move dead eggs data into Egg Development column. We only have ~50 with dead eggs over 20%, so we'll just note all as having dead eggs
fem_crabs <- fem_crabs %>%
  mutate(Egg.Development = ifelse(Egg.Condition == "Dead_eggs_over_20pct", "Dead_Eggs", as.character(Egg.Development)))
fem_crabs <- fem_crabs %>%
  mutate(Egg.Development = ifelse(Egg.Condition == "Dead_eggs_under_20pct", "Dead_Eggs", as.character(Egg.Development)))

# Only three crabs have eyed eggs, we'll just remove those
fem_crabs <- fem_crabs %>%
  filter(Egg.Development != "Eyed")

# Change all crabs with a recruit status of Juvenile Female to Egg Development = Juvenile
fem_crabs <- fem_crabs %>%
  mutate(Egg.Development = ifelse(Recruit.Status == "Juvenile_Female", "Juvenile", as.character(Egg.Development)))

# Alright, we can remove the Egg Condition column
fem_crabs <- fem_crabs %>%
  dplyr::select(-Egg.Condition)

# If a crab has an egg percent of zero (and isn't a juvenile or barren), change to NA in egg development (since we don't know if barren or matted)
fem_crabs <- fem_crabs %>%
  mutate(Egg.Development = ifelse(Egg.Percent == 0 & (Egg.Development == "Dead_Eggs" | Egg.Development == "Uneyed"), NA, as.character(Egg.Development)))

# If a crab is juvenile or barren, change egg percent to zero
fem_crabs <- fem_crabs %>%
  mutate(Egg.Percent = ifelse(Egg.Percent != 0 & (Egg.Development == "Barren_Clean" | Egg.Development == "Barren_Matted" | Egg.Development == "Juvenile"), NA, Egg.Percent))

# See how many NAs we have
colSums(is.na(fem_crabs))

# Drop all rows with NAs
fem_crabs <- na.omit(fem_crabs)
# Great, we've got around 25,000 rows! Neat stuff.

#### Re-scale all variables for our new dataset

# Subtract 2004 from all years, so that our earliest year is 1
fem_crabs$s.Year <- fem_crabs$Year-(min(fem_crabs$Year)-1)

# Scale latitude, longitude, Julian day, depth, and temperature
fem_crabs$s.Latitude <- scale(fem_crabs$Latitude)
fem_crabs$s.Longitude <- scale(fem_crabs$Longitude)
fem_crabs$s.Jul.Day <- scale(fem_crabs$Jul.Day)
fem_crabs$s.Depth <- scale(fem_crabs$Depth)
fem_crabs$s.Temp <- scale(fem_crabs$Temp)
# Just need to scale CW once this time
fem_crabs$s.CW <- scale(fem_crabs$CW)
# Need to also do egg percent this time!
fem_crabs$s.Egg.Percent <- scale(fem_crabs$Egg.Percent)

colnames(fem_crabs)
```



### Select variables to be used in model

```{r}
# Select all variables to be used in our model for female crabs
femcrabs_dat <- fem_crabs %>%
  dplyr::select(c(s.Year, Site, s.CW, Shell.Condition, Egg.Development, Leg.Condition, Bitter, s.Egg.Percent, Blackmat, s.Latitude, s.Jul.Day, s.Depth, s.Temp))

# Select independent variables
modeled_vars <- names(femcrabs_dat)
modeled_vars <- modeled_vars[!modeled_vars %in% c("s.Year", "Site", "Bitter")]

# Initialize dataframe with model values
AIC_vals <- matrix(nrow = length(modeled_vars), ncol = 2)

# Create a null model and get AIC
null_mod <- glmmTMB(Bitter ~ (1 | Site) + (1 | s.Year), 
                  data = femcrabs_dat,
                  family = binomial,
                  na.action = "na.fail")

AIC_null <- extractAIC(null_mod)[2]
AIC_vals[1, 1] <- "null_mod"
AIC_vals[1, 2] <- extractAIC(null_mod)[2] - AIC_null

# Create for loop to extract AIC for all variables
for (i in 1:length(modeled_vars)){
  my_formula = paste0("Bitter ~ ", modeled_vars[i], " + (1 | Site) + (1 | s.Year)")
  test_mod <- glmer(my_formula,
                    data = femcrabs_dat,
                    family = binomial)
  
  AIC_vals[i, 1] <- modeled_vars[i]
  AIC_vals[i, 2] <- extractAIC(test_mod)[2] - AIC_null
}
beep()



# See which variables improve the model the most
AIC_vals[order(as.numeric(AIC_vals[, 2])), ]

```

Here's the order of the impact of our variables, from most to least impactful. 

Shell Condition
Egg Percent
Egg Development
Black Mat
Leg Condition
CW
Temperature
Depth
Latitude
[Null model]
Julian Day

### Build model

Alright, we'll again use glmmTMB to build a full model, then we'll check for collinearity

```{r}
fem_full_model <- glmmTMB(Bitter ~ Shell.Condition + s.Egg.Percent + Egg.Development + Blackmat + Leg.Condition + s.CW + s.Temp + s.Depth + s.Latitude + s.Jul.Day + (1 | Site) + (1 | s.Year),
                       data = femcrabs_dat,
                       family = binomial,
                       na.action = "na.fail"              # This line is for the dredge() function used later
                       )

check_collinearity(fem_full_model)

# Wow, everything looks great! Was worried about having issues with egg percent and egg development (since barren = 0), but apparently all good!
```

### Model Diagnostics

Now that we have produced a full model, before we start fine-tuning it, we need to do some diagnostics to ensure it meets our assumptions

```{r}
# Simulate residuals and plot
testOutliers(fem_full_model, alternative = "two.sided", margin = "both", type = "bootstrap", plot = TRUE)
simulateResiduals(fem_full_model, plot = TRUE)

# Perform ANOVA on model fits
car::Anova(fem_full_model)

# Alright, looks like in our full model, everything is significant except Black Mat and depth, with latitude and leg condition being just barely significant.

# Test for effects. You can plot these all together with plot(allEffects(fem_full_model)), but that gets crowded visually
plot(predictorEffect("Shell.Condition", fem_full_model))
plot(predictorEffect("s.Egg.Percent", fem_full_model))
plot(predictorEffect("Egg.Development", fem_full_model))
plot(predictorEffect("Blackmat", fem_full_model))
plot(predictorEffect("Leg.Condition", fem_full_model))
plot(predictorEffect("s.CW", fem_full_model))
plot(predictorEffect("s.Temp", fem_full_model))
plot(predictorEffect("s.Depth", fem_full_model))
plot(predictorEffect("s.Latitude", fem_full_model))
plot(predictorEffect("s.Jul.Day", fem_full_model))

```

           Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI
 Shell.Condition 1.14 [1.13, 1.16]         1.07      0.87     [0.86, 0.89]
   s.Egg.Percent 1.35 [1.33, 1.37]         1.16      0.74     [0.73, 0.75]
 Egg.Development 1.48 [1.45, 1.50]         1.22      0.68     [0.67, 0.69]
        Blackmat 1.03 [1.02, 1.04]         1.01      0.97     [0.96, 0.98]
   Leg.Condition 1.01 [1.00, 1.04]         1.01      0.99     [0.97, 1.00]
            s.CW 1.01 [1.00, 1.03]         1.01      0.99     [0.97, 1.00]
          s.Temp 1.71 [1.68, 1.74]         1.31      0.58     [0.57, 0.59]
         s.Depth 1.80 [1.77, 1.83]         1.34      0.56     [0.55, 0.57]
      s.Latitude 1.16 [1.15, 1.18]         1.08      0.86     [0.85, 0.87]
       s.Jul.Day 1.70 [1.67, 1.73]         1.31      0.59     [0.58, 0.60]
### Dredging

We will now use the dredge() function from the MuMIn package to go through each of our model possibilities and select an optimal full model using AIC.

```{r}
fem_all_mods <- dredge(fem_full_model, beta = "none",
       eval = TRUE,
       rank = "AICc")

plot(fem_all_mods)

# We have one very good model (weight = 0.30), a good model (weight = 0.18), 
# five alright models (weights < .10 & > 0.05), and seven meh models (weights < 0.05 & > 0.01)
fem_best_mods <- get.models(fem_all_mods, subset = weight > 0.01)

summary(fem_best_mods)

# See what each of the models look like. Comments compare it to the best model (1)
fem_best_mods[1]                               
fem_best_mods[2] # Adds depth
# Start of alright models
fem_best_mods[3] # Drops Black Mat
fem_best_mods[4] # Drops latitude
fem_best_mods[5] # Adds depth, drops latitude
fem_best_mods[6] # Drops leg condition
fem_best_mods[7] # Adds depth, drops Black Mat
# Start of meh models
fem_best_mods[8] # Drops leg condition, adds depth
fem_best_mods[9] # Drops Black Mat and latitude
fem_best_mods[10] # Drops Black Mat and latitude, adds depth
fem_best_mods[11] # Drops Black Mat and leg condition
fem_best_mods[12] # Drops leg condition and latitude
fem_best_mods[13] # Drops leg condition and latitude, adds depth
fem_best_mods[14] # Drops Black Mat and leg condition, adds depth

# Average models based on AICc
fem_avg_model <- model.avg(fem_best_mods, beta = "none")

# See what that average model looks like
fem_avg_model$coefficients
summary(fem_avg_model)
```

### More tests 
```{r}
#### Test dispersion of each of our models

# Note: they're all going to fail the KS test, just because our sample size is huge. As long as the QQ plot looks fine, no cause for concern. 

# First plot: a Q-Q plot and a plot of residuals. THe latter should appear as a line around 0.5, followed by a few dots up at 1

# Second plot: Standardized residuals for crabs predicted as bitter and not bitter. Has the number of the model in the title (1 = best model, 14 = worst model)

# Third plot: Dispersion test of residuals. Red line should be approx around mean, p value should be not significant

# Fourth plot: Dispersion test for zero inflation. Red line should be approx around mean, p value should be not significant

for (i in 1:length(fem_best_mods)){
  print(paste("Model", i))
  simulationOutput <- simulateResiduals(fittedModel = fem_best_mods[i][[1]], plot = TRUE) 
  plotResiduals(simulationOutput, femcrabs_dat$Bitter, quantreg = TRUE, rank = TRUE, main = paste("Model", i))
  testDispersion(simulationOutput, alternative = "greater", plot = TRUE)
  testZeroInflation(simulationOutput)
}

# Lovely, all models look just fine!
```
Quick break just so we can visualize plots easier
```{r}
# Create for loop simulating data and plotting results for each model
for (i in 1:length(fem_best_mods)) {
  # Simulate data, see how accurate models are. This uses our custom function sim_dat()
  sim_data <- sim_dat(model = fem_best_mods[i][[1]], data = femcrabs_dat, num_sims = 1000)
  # Plot simulated data with a red line as the real data
  plot(sim_data$sim_num, sim_data$total_bitter, main = paste("Model", i)) +
    abline(h = sum(femcrabs_dat$Bitter == 1), col = "red")
  # Plot percent change from real data
  hist(sim_data$pct_change_from_data, main = paste("Histogram of Model", i))
  # Extract mean percent change from real data
  print(mean(sim_data$pct_change_from_data))
  
  
}
```
Quick break for easier graphing 

```{r}
# Do we want to use fitted() or predict() too?
pred_mod <- fitted(fem_best_mods[1][[1]], newdata = femcrabs_dat)
```

```{r}
summary(fem_avg_model)
        
```


# MODEL OF MALE CRABS

This model will include all male crabs with chela height measurements

### Filter and re-scale to get correct data for model

```{r}
# Select only male crabs
masc_crabs <- crab_dat %>%
  filter(Sex == "1")

# Drop egg columns
masc_crabs <- masc_crabs %>%
  select(-c(Egg.Development, Egg.Condition, Egg.Percent))

# Drop scaled columns - we'll scale them again
masc_crabs <- masc_crabs %>%
  select(-contains("s."))

# We'll use the ratio of chela height to carapace width to indicate crab maturity
# Note: This is using the EBS line for height-CW, will have to get the SE AK ratio later
# EBS equation = ln(chela_ht) = (1.189*ln(CW)) - 2.674
# Create new column for maturity line. Remember, log() computes ln, R is weird like that 
# Also, male crabs with a CW < 60 are immature
masc_crabs$mat_line <- (1.189 * log(masc_crabs$CW)) - 2.674

# Drop crabs without chela height value
masc_crabs <- masc_crabs[!is.na(masc_crabs$Chela.Ht),]

# Calculate maturity value. 
masc_crabs$mat_val <- log(masc_crabs$Chela.Ht)

# Create column for maturity status. If maturity value is greater than maturity line and CW >= 60 cm, is mature
masc_crabs <- masc_crabs %>%
  mutate(mat_stat = case_when(
    mat_val <= mat_line | CW <= 60 ~ "1",
    mat_val > mat_line ~ "2"
    ))

# Remove maturity value and line columns, no longer needed
masc_crabs <- masc_crabs %>%
  select(-c(mat_val, mat_line))

# See how many NAs we have
colSums(is.na(masc_crabs))

# Great, we've got around 25,000 rows! Neat stuff.

#### Re-scale all variables for our new dataset

# Subtract 2004 from all years, so that our earliest year is 1
masc_crabs$s.Year <- masc_crabs$Year-(min(masc_crabs$Year)-1)

# Scale latitude, longitude, Julian day, depth, and temperature
masc_crabs$s.Latitude <- scale(masc_crabs$Latitude)
masc_crabs$s.Longitude <- scale(masc_crabs$Longitude)
masc_crabs$s.Jul.Day <- scale(masc_crabs$Jul.Day)
masc_crabs$s.Depth <- scale(masc_crabs$Depth)
masc_crabs$s.Temp <- scale(masc_crabs$Temp)
# Just need to scale CW once this time
masc_crabs$s.CW <- scale(masc_crabs$CW)

colnames(masc_crabs)
```



### Select variables to be used in model

```{r}
# Select all variables to be used in our model for male crabs
masccrabs_dat <- masc_crabs %>%
  dplyr::select(c(s.Year, Site, s.CW, Shell.Condition, Leg.Condition, Bitter, Blackmat, s.Latitude, s.Jul.Day, s.Depth, s.Temp, mat_stat))

# Select independent variables
modeled_vars <- names(masccrabs_dat)
modeled_vars <- modeled_vars[!modeled_vars %in% c("s.Year", "Site", "Bitter")]

# Initialize dataframe with model values
AIC_vals <- matrix(nrow = length(modeled_vars), ncol = 2)

# Create a null model and get AIC
null_mod <- glmmTMB(Bitter ~ (1 | Site) + (1 | s.Year), 
                  data = masccrabs_dat,
                  family = binomial,
                  na.action = "na.fail")

AIC_null <- extractAIC(null_mod)[2]
AIC_vals[1, 1] <- "null_mod"
AIC_vals[1, 2] <- extractAIC(null_mod)[2] - AIC_null

# Create for loop to extract AIC for all variables
for (i in 1:length(modeled_vars)){
  my_formula = paste0("Bitter ~ ", modeled_vars[i], " + (1 | Site) + (1 | s.Year)")
  test_mod <- glmer(my_formula,
                    data = masccrabs_dat,
                    family = binomial)
  
  AIC_vals[i, 1] <- modeled_vars[i]
  AIC_vals[i, 2] <- extractAIC(test_mod)[2] - AIC_null
}
beep()



# See which variables improve the model the most
AIC_vals[order(as.numeric(AIC_vals[, 2])), ]

```

Here's the order of the impact of our variables, from most to least impactful. 

Shell Condition
Maturity
Carapace width
Temperature
Julian day
Black Mat infection
Leg condition
[Null model]
Latitude
Depth

### Build model

Alright, we'll again use glmmTMB to build a full model, then we'll check for collinearity

```{r}
masc_full_model <- glmmTMB(Bitter ~ Shell.Condition + mat_stat + s.CW + s.Temp + s.Jul.Day + Blackmat + Leg.Condition + s.Latitude + s.Depth + (1 | Site) + (1 | s.Year),
                       data = masccrabs_dat,
                       family = binomial,
                       na.action = "na.fail"              # This line is for the dredge() function used later
                       )

check_collinearity(masc_full_model)

# Wow, everything looks great! Was worried about having issues with egg percent and egg development (since barren = 0), but apparently all good!
```

### Model Diagnostics

Now that we have produced a full model, before we start fine-tuning it, we need to do some diagnostics to ensure it meets our assumptions

```{r}
# Simulate residuals and plot
testOutliers(masc_full_model, alternative = "two.sided", margin = "both", type = "bootstrap", plot = TRUE)
simulateResiduals(masc_full_model, plot = TRUE)

# Perform ANOVA on model fits
car::Anova(masc_full_model)

# Alright, looks like in our full model, shell condition, maturity, CW, temperature, and leg condition are significant, while Julian day, Black Mat, Latitude, and Depth aren't.

# Test for effects. You can plot these all together with plot(allEffects(masc_full_model)), but that gets crowded visually
plot(predictorEffect("Shell.Condition", masc_full_model))
plot(predictorEffect("mat_stat", masc_full_model))
plot(predictorEffect("s.CW", masc_full_model))
plot(predictorEffect("s.Temp", masc_full_model))
plot(predictorEffect("s.Jul.Day", masc_full_model))
plot(predictorEffect("Blackmat", masc_full_model))
plot(predictorEffect("Leg.Condition", masc_full_model))
plot(predictorEffect("s.Latitude", masc_full_model))
plot(predictorEffect("s.Depth", masc_full_model))
```

           Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI
 Shell.Condition 1.14 [1.13, 1.16]         1.07      0.87     [0.86, 0.89]
   s.Egg.Percent 1.35 [1.33, 1.37]         1.16      0.74     [0.73, 0.75]
 Egg.Development 1.48 [1.45, 1.50]         1.22      0.68     [0.67, 0.69]
        Blackmat 1.03 [1.02, 1.04]         1.01      0.97     [0.96, 0.98]
   Leg.Condition 1.01 [1.00, 1.04]         1.01      0.99     [0.97, 1.00]
            s.CW 1.01 [1.00, 1.03]         1.01      0.99     [0.97, 1.00]
          s.Temp 1.71 [1.68, 1.74]         1.31      0.58     [0.57, 0.59]
         s.Depth 1.80 [1.77, 1.83]         1.34      0.56     [0.55, 0.57]
      s.Latitude 1.16 [1.15, 1.18]         1.08      0.86     [0.85, 0.87]
       s.Jul.Day 1.70 [1.67, 1.73]         1.31      0.59     [0.58, 0.60]
### Dredging

We will now use the dredge() function from the MuMIn package to go through each of our model possibilities and select an optimal full model using AIC.

```{r}
masc_all_mods <- dredge(masc_full_model, beta = "none",
       eval = TRUE,
       rank = "AICc")

plot(masc_all_mods)

# Looks like we have 16 total models above 0.01. Of these, two are best (combined weight: 0.39), and an additional 6 are decent (combined weight with the two best: combined weight: 0.83). There are then 9 more models with weights from 0.3 to 0.1

masc_best_mods <- get.models(masc_all_mods, subset = weight > 0.01)

# See what each of the top 8 models look like
masc_best_mods[1]
masc_best_mods[2]
masc_best_mods[3]
masc_best_mods[4]
masc_best_mods[5]
masc_best_mods[6]
masc_best_mods[7]
masc_best_mods[8]

# Average models based on AICc
masc_avg_model <- model.avg(masc_best_mods, beta = "none")

# See what that average model looks like
masc_avg_model$coefficients
summary(masc_avg_model)
```

# MODEL W MATURITY

Hey, now that we have mature/immature status for both males and females, why not do another full model? This time, it'll examine maturity as well - same as the model of all crabs, but only including crabs with maturity status (and, of course, adding maturity status as a variable)


This model will include all crabs with maturity measurements

### Filter and re-scale to get correct data for model

```{r}
# Select only male crabs
masc_crabs <- crab_dat %>%
  filter(Sex == "1")

# Drop egg columns
masc_crabs <- masc_crabs %>%
  select(-c(Egg.Development, Egg.Condition, Egg.Percent))

# Drop scaled columns - we'll scale them again
masc_crabs <- masc_crabs %>%
  select(-contains("s."))

# We'll use the ratio of chela height to carapace width to indicate crab maturity
# Note: This is using the EBS line for height-CW, will have to get the SE AK ratio later
# EBS equation = ln(chela_ht) = (1.189*ln(CW)) - 2.674
# Create new column for maturity line. Remember, log() computes ln, R is weird like that 
# Also, male crabs with a CW < 60 are immature
masc_crabs$mat_line <- (1.189 * log(masc_crabs$CW)) - 2.674

# Drop crabs without chela height value
masc_crabs <- masc_crabs[!is.na(masc_crabs$Chela.Ht),]

# Drop crabs 

# Calculate maturity value. If greater than maturity line and CW >= 60 cm, is mature
masc_crabs$mat_val <- log(masc_crabs$Chela.Ht)

# Create column for maturity status
masc_crabs <- masc_crabs %>%
  mutate(mat_stat = case_when(
    mat_val <= mat_line | CW <= 60 ~ "1",
    mat_val > mat_line ~ "2"
    ))

# Remove maturity value and line columns, no longer needed
masc_crabs <- masc_crabs %>%
  select(-c(mat_val, mat_line))

# See how many NAs we have
colSums(is.na(masc_crabs))

# Great, we've got around 25,000 rows! Neat stuff.

#### Re-scale all variables for our new dataset

# Subtract 2004 from all years, so that our earliest year is 1
masc_crabs$s.Year <- masc_crabs$Year-(min(masc_crabs$Year)-1)

# Scale latitude, longitude, Julian day, depth, and temperature
masc_crabs$s.Latitude <- scale(masc_crabs$Latitude)
masc_crabs$s.Longitude <- scale(masc_crabs$Longitude)
masc_crabs$s.Jul.Day <- scale(masc_crabs$Jul.Day)
masc_crabs$s.Depth <- scale(masc_crabs$Depth)
masc_crabs$s.Temp <- scale(masc_crabs$Temp)
# Just need to scale CW once this time
masc_crabs$s.CW <- scale(masc_crabs$CW)

colnames(masc_crabs)
```




### Select variables to be used in model

```{r}
# Select all variables to be used in our model for male crabs
masccrabs_dat <- masc_crabs %>%
  dplyr::select(c(s.Year, Site, s.CW, Shell.Condition, Leg.Condition, Bitter, Blackmat, s.Latitude, s.Jul.Day, s.Depth, s.Temp, mat_stat))

# Select independent variables
modeled_vars <- names(masccrabs_dat)
modeled_vars <- modeled_vars[!modeled_vars %in% c("s.Year", "Site", "Bitter")]

# Initialize dataframe with model values
AIC_vals <- matrix(nrow = length(modeled_vars), ncol = 2)

# Create a null model and get AIC
null_mod <- glmmTMB(Bitter ~ (1 | Site) + (1 | s.Year), 
                  data = masccrabs_dat,
                  family = binomial,
                  na.action = "na.fail")

AIC_null <- extractAIC(null_mod)[2]
AIC_vals[1, 1] <- "null_mod"
AIC_vals[1, 2] <- extractAIC(null_mod)[2] - AIC_null

# Create for loop to extract AIC for all variables
for (i in 1:length(modeled_vars)){
  my_formula = paste0("Bitter ~ ", modeled_vars[i], " + (1 | Site) + (1 | s.Year)")
  test_mod <- glmer(my_formula,
                    data = masccrabs_dat,
                    family = binomial)
  
  AIC_vals[i, 1] <- modeled_vars[i]
  AIC_vals[i, 2] <- extractAIC(test_mod)[2] - AIC_null
}
beep()



# See which variables improve the model the most
AIC_vals[order(as.numeric(AIC_vals[, 2])), ]

```

Here's the order of the impact of our variables, from most to least impactful. 

Shell Condition
Maturity
Carapace width
Temperature
Julian day
Black Mat infection
Leg condition
[Null model]
Latitude
Depth

### Build model

Alright, we'll again use glmmTMB to build a full model, then we'll check for collinearity

```{r}
masc_full_model <- glmmTMB(Bitter ~ Shell.Condition + mat_stat + s.CW + s.Temp + s.Jul.Day + Blackmat + Leg.Condition + s.Latitude + s.Depth + (1 | Site) + (1 | s.Year),
                       data = masccrabs_dat,
                       family = binomial,
                       na.action = "na.fail"              # This line is for the dredge() function used later
                       )

check_collinearity(masc_full_model)

# Wow, everything looks great! Was worried about having issues with egg percent and egg development (since barren = 0), but apparently all good!
```


### Model Diagnostics

Now that we have produced a full model, before we start fine-tuning it, we need to do some diagnostics to ensure it meets our assumptions

```{r}
# Simulate residuals and plot
testOutliers(masc_full_model, alternative = "two.sided", margin = "both", type = "bootstrap", plot = TRUE)
simulateResiduals(masc_full_model, plot = TRUE)

# Perform ANOVA on model fits
car::Anova(masc_full_model)

# Alright, looks like in our full model, shell condition, maturity, CW, temperature, and leg condition are significant, while Julian day, Black Mat, Latitude, and Depth aren't.

# Test for effects. You can plot these all together with plot(allEffects(masc_full_model)), but that gets crowded visually
plot(predictorEffect("Shell.Condition", masc_full_model))
plot(predictorEffect("mat_stat", masc_full_model))
plot(predictorEffect("s.CW", masc_full_model))
plot(predictorEffect("s.Temp", masc_full_model))
plot(predictorEffect("s.Jul.Day", masc_full_model))
plot(predictorEffect("Blackmat", masc_full_model))
plot(predictorEffect("Leg.Condition", masc_full_model))
plot(predictorEffect("s.Latitude", masc_full_model))
plot(predictorEffect("s.Depth", masc_full_model))
```

### Dredging

We will now use the dredge() function from the MuMIn package to go through each of our model possibilities and select an optimal full model using AIC.

```{r}
masc_all_mods <- dredge(masc_full_model, beta = "none",
       eval = TRUE,
       rank = "AICc")

plot(masc_all_mods)

# Looks like we have four good models (weights > 0.2) and four marginal models (weights between 0.04 and 0.01)
masc_best_mods <- get.models(masc_all_mods, subset = weight > 0.01)

# See what each of the best models look like
masc_best_mods[1]
masc_best_mods[2]
masc_best_mods[3]
masc_best_mods[4]
masc_best_mods[5]
masc_best_mods[6]
masc_best_mods[7]
masc_best_mods[8]

# Average models based on AICc
masc_avg_model <- model.avg(masc_best_mods, beta = "none")

# See what that average model looks like
masc_avg_model$coefficients
summary(masc_avg_model)
```